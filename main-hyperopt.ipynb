{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10471355,"sourceType":"datasetVersion","datasetId":6483657},{"sourceId":10542548,"sourceType":"datasetVersion","datasetId":6523213},{"sourceId":10596106,"sourceType":"datasetVersion","datasetId":6558503}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nlpaug\n!pip install optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:04:18.348644Z","iopub.execute_input":"2025-01-27T21:04:18.348941Z","iopub.status.idle":"2025-01-27T21:04:27.737398Z","shell.execute_reply.started":"2025-01-27T21:04:18.348918Z","shell.execute_reply":"2025-01-27T21:04:27.736356Z"}},"outputs":[{"name":"stdout","text":"Collecting nlpaug\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.26.4)\nRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.2.2)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.32.3)\nRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.16.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.12.14)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.6)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.2->nlpaug) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nlpaug\nSuccessfully installed nlpaug-1.1.11\nRequirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.1.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.0)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\nRequirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.8)\nRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->optuna) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn.utils.prune as prune\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW, lr_scheduler\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertConfig\nfrom sklearn.metrics import f1_score, confusion_matrix, balanced_accuracy_score, precision_score, recall_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nlpaug.augmenter.word as naw\nimport optuna\nimport shutil\nimport zipfile\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:04:27.738617Z","iopub.execute_input":"2025-01-27T21:04:27.738920Z","iopub.status.idle":"2025-01-27T21:05:25.901888Z","shell.execute_reply.started":"2025-01-27T21:04:27.738896Z","shell.execute_reply":"2025-01-27T21:05:25.901239Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Ensure output directory exists\noutput_dir = \"/kaggle/working/output\"\nos.makedirs(output_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:25.903143Z","iopub.execute_input":"2025-01-27T21:05:25.903652Z","iopub.status.idle":"2025-01-27T21:05:25.906921Z","shell.execute_reply.started":"2025-01-27T21:05:25.903630Z","shell.execute_reply":"2025-01-27T21:05:25.906303Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/balancedfull/df1.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/balancedfull/df2.csv\")\ndf3 = pd.read_csv(\"/kaggle/input/balancedfull/df3.csv\")\ndf4 = pd.read_csv(\"/kaggle/input/balancedfull/df4.csv\")\ndf5 = pd.read_csv(\"/kaggle/input/balancedfull/df5.csv\")\n\ndf_balanced1 = pd.read_csv(\"/kaggle/input/balancedfull/df_balanced1.csv\")\ndf_balanced2 = pd.read_csv(\"/kaggle/input/balancedfull/df_balanced2.csv\")\ndf_balanced3 = pd.read_csv(\"/kaggle/input/balancedfull/df_balanced3.csv\")\ndf_balanced4 = pd.read_csv(\"/kaggle/input/balancedfull/df_balanced4.csv\")\ndf_balanced5 = pd.read_csv(\"/kaggle/input/balancedfull/df_balanced5.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:25.908101Z","iopub.execute_input":"2025-01-27T21:05:25.908400Z","iopub.status.idle":"2025-01-27T21:05:26.283862Z","shell.execute_reply.started":"2025-01-27T21:05:25.908371Z","shell.execute_reply":"2025-01-27T21:05:26.282333Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df1_text = df1['quote']\ndf2_text = df2['quote']\ndf3_text = df3['quote']\ndf4_text = df4['quote']\ndf5_text = df5['quote']\ndf1_label = df1['numeric_label']\ndf2_label = df2['numeric_label']\ndf3_label = df3['numeric_label']\ndf4_label = df4['numeric_label']\ndf5_label = df5['numeric_label']\ndf_balanced1_text = df_balanced1['quote']\ndf_balanced2_text = df_balanced2['quote']\ndf_balanced3_text = df_balanced3['quote']\ndf_balanced4_text = df_balanced4['quote']\ndf_balanced5_text = df_balanced5['quote']\ndf_balanced1_label = df_balanced1['numeric_label']\ndf_balanced2_label = df_balanced2['numeric_label']\ndf_balanced3_label = df_balanced3['numeric_label']\ndf_balanced4_label = df_balanced4['numeric_label']\ndf_balanced5_label = df_balanced5['numeric_label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:26.284876Z","iopub.execute_input":"2025-01-27T21:05:26.285159Z","iopub.status.idle":"2025-01-27T21:05:26.298733Z","shell.execute_reply.started":"2025-01-27T21:05:26.285125Z","shell.execute_reply":"2025-01-27T21:05:26.298102Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Load and prepare data\n# original\n# df = pd.read_parquet(\"/kaggle/input/train-parquet\")\n# df['label_int'] = df['label'].str.split(\"_\").str[0].astype('int')\n\n# texts = df[\"quote\"].to_list()\n# labels = df[\"label_int\"].to_list()\n\n# X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:26.299639Z","iopub.execute_input":"2025-01-27T21:05:26.299889Z","iopub.status.idle":"2025-01-27T21:05:26.320410Z","shell.execute_reply.started":"2025-01-27T21:05:26.299857Z","shell.execute_reply":"2025-01-27T21:05:26.319855Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# # augmented \n# train1 = pd.read_csv('/kaggle/input/balanced/train1.csv')\n# train2 = pd.read_csv('/kaggle/input/balanced/train2.csv')\n# train3 = pd.read_csv('/kaggle/input/balanced/train3.csv')\n# train4 = pd.read_csv('/kaggle/input/balanced/train4.csv')\n\n# datasets = [train1, train2, train3, train4]\n\n# # Extract quotes and labels using list comprehension\n# texts = [ds['quote'] for ds in datasets]\n# labels = [ds['numeric_label'] for ds in datasets]\n\n# # Concatenate all texts and labels using pandas.concat\n# train1234_texts = pd.concat(texts, ignore_index=True)\n# train1234_labels = pd.concat(labels, ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:26.321215Z","iopub.execute_input":"2025-01-27T21:05:26.321512Z","iopub.status.idle":"2025-01-27T21:05:26.336614Z","shell.execute_reply.started":"2025-01-27T21:05:26.321464Z","shell.execute_reply":"2025-01-27T21:05:26.335993Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:26.338998Z","iopub.execute_input":"2025-01-27T21:05:26.339197Z","iopub.status.idle":"2025-01-27T21:05:26.434981Z","shell.execute_reply.started":"2025-01-27T21:05:26.339180Z","shell.execute_reply":"2025-01-27T21:05:26.434233Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Create dictionary for label names\nlabel_dict = df1[['numeric_label', 'label']].drop_duplicates().set_index('numeric_label')['label'].to_dict()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:26.436357Z","iopub.execute_input":"2025-01-27T21:05:26.436597Z","iopub.status.idle":"2025-01-27T21:05:26.470838Z","shell.execute_reply.started":"2025-01-27T21:05:26.436578Z","shell.execute_reply":"2025-01-27T21:05:26.470080Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\nMAX_LENGTH = 365\n\n# Dataset and DataLoader preparation\nclass QuotesDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ndef encode_data(tokenizer, texts, labels, max_length):\n    try:\n        if isinstance(texts, pd.Series):\n            texts = texts.tolist()\n        if isinstance(labels, pd.Series):\n            labels = labels.tolist()\n            \n        encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n        return QuotesDataset(encodings, labels)\n\n    except Exception as e:\n        print(f\"Error during tokenization: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:26.471715Z","iopub.execute_input":"2025-01-27T21:05:26.471992Z","iopub.status.idle":"2025-01-27T21:05:27.357443Z","shell.execute_reply.started":"2025-01-27T21:05:26.471964Z","shell.execute_reply":"2025-01-27T21:05:27.356634Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bda24abebd34f45955ab14b5d51cc7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fea9d2430cb4b2fa41e9d4b988a1a02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"209335907a684345918fdec0b25a01e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e97fe9b298b444009d8a4aaa8eb5c0ae"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"df1_dataset = encode_data(tokenizer, df1_text, df1_label, MAX_LENGTH)\ndf2_dataset = encode_data(tokenizer, df2_text, df2_label, MAX_LENGTH)\ndf3_dataset = encode_data(tokenizer, df3_text, df3_label, MAX_LENGTH)\ndf4_dataset = encode_data(tokenizer, df4_text, df4_label, MAX_LENGTH)\ndf5_dataset = encode_data(tokenizer, df5_text, df5_label, MAX_LENGTH)\ndf_balanced1_dataset = encode_data(tokenizer, df_balanced1_text, df_balanced1_label, MAX_LENGTH)\ndf_balanced2_dataset = encode_data(tokenizer, df_balanced2_text, df_balanced2_label, MAX_LENGTH)\ndf_balanced3_dataset = encode_data(tokenizer, df_balanced3_text, df_balanced3_label, MAX_LENGTH)\ndf_balanced4_dataset = encode_data(tokenizer, df_balanced4_text, df_balanced4_label, MAX_LENGTH)\ndf_balanced5_dataset = encode_data(tokenizer, df_balanced5_text, df_balanced5_label, MAX_LENGTH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:27.358323Z","iopub.execute_input":"2025-01-27T21:05:27.358546Z","iopub.status.idle":"2025-01-27T21:05:51.864253Z","shell.execute_reply.started":"2025-01-27T21:05:27.358528Z","shell.execute_reply":"2025-01-27T21:05:51.863571Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"datasets = [df1_dataset, df2_dataset, df3_dataset, df4_dataset, df5_dataset]\nbalanced_datasets = [df_balanced1_dataset, df_balanced2_dataset, df_balanced3_dataset, df_balanced4_dataset, df_balanced5_dataset]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:51.865002Z","iopub.execute_input":"2025-01-27T21:05:51.865212Z","iopub.status.idle":"2025-01-27T21:05:51.868937Z","shell.execute_reply.started":"2025-01-27T21:05:51.865194Z","shell.execute_reply":"2025-01-27T21:05:51.868006Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# train_dataset = encode_data(tokenizer, X_train, y_train, MAX_LENGTH)\n# train1234_dataset = encode_data(tokenizer, train1234_texts, train1234_labels, MAX_LENGTH)\n# val_dataset = encode_data(tokenizer, X_test, y_test, MAX_LENGTH)\n\n# train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n# train1234_loader = DataLoader(train1234_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n# val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:51.869892Z","iopub.execute_input":"2025-01-27T21:05:51.870197Z","iopub.status.idle":"2025-01-27T21:05:51.929590Z","shell.execute_reply.started":"2025-01-27T21:05:51.870169Z","shell.execute_reply":"2025-01-27T21:05:51.928947Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"- Above is the basic data setup. Now train + hyperparam tune the model\n- Start with defining some functions to be used in objective","metadata":{}},{"cell_type":"code","source":"# # Changes the layers freezed and drop out rate \n# def modify_model(model, num_trainable_layers, dropout_rate):\n#     # Freeze layers: only the last 'num_trainable_layers' are trainable\n#     total_layers = len(model.distilbert.transformer.layer)\n#     for layer_index, layer in enumerate(model.distilbert.transformer.layer):\n#         if layer_index < total_layers - num_trainable_layers:\n#             for param in layer.parameters():\n#                 param.requires_grad = False\n#                 prune.l1_unstructured(param, 'weight', amount=dropout_rate)\n\n#     # Adjust dropout rates in applicable transformer layers\n#     for layer in model.distilbert.transformer.layer:\n#         layer.attention.dropout.p = dropout_rate\n#         layer.ffn.dropout.p = dropout_rate\n\n#     return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:51.930461Z","iopub.execute_input":"2025-01-27T21:05:51.930777Z","iopub.status.idle":"2025-01-27T21:05:51.944991Z","shell.execute_reply.started":"2025-01-27T21:05:51.930750Z","shell.execute_reply":"2025-01-27T21:05:51.944411Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def modify_model(model, num_trainable_layers, dropout_rate, pruning_rate):\n    # Freeze layers: only the last 'num_trainable_layers' are trainable\n    total_layers = len(model.distilbert.transformer.layer)\n    \n    for layer_index, layer in enumerate(model.distilbert.transformer.layer):\n        if layer_index < total_layers - num_trainable_layers:\n            # Freeze layers by disabling gradient computation\n            for param in layer.parameters():\n                param.requires_grad = False\n        else:\n            # Pruning only specific parts if applicable\n            # Ensure 'weight' or 'bias' is a valid attribute, this is an example for weight pruning\n            if hasattr(layer, 'weight'):\n                prune.l1_unstructured(layer, name='weight', amount=pruning_rate)\n\n        # Adjust dropout rates in applicable transformer layers\n        layer.attention.dropout.p = dropout_rate\n        layer.ffn.dropout.p = dropout_rate\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:51.945813Z","iopub.execute_input":"2025-01-27T21:05:51.946007Z","iopub.status.idle":"2025-01-27T21:05:51.960160Z","shell.execute_reply.started":"2025-01-27T21:05:51.945989Z","shell.execute_reply":"2025-01-27T21:05:51.959635Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Model training \ndef train_one_epoch(model, train_loader, optimizer, grad_clip, device):\n    model.train()\n    train_loss = 0\n    correct_train = 0\n    total_train = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n        optimizer.step()\n        train_loss += loss.item()\n        predictions = torch.argmax(outputs.logits, dim=-1)\n        correct_train += (predictions == batch['labels']).sum().item()\n        total_train += batch['labels'].size(0)\n    average_loss = train_loss / len(train_loader)\n    accuracy = correct_train / total_train\n    return average_loss, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:51.960839Z","iopub.execute_input":"2025-01-27T21:05:51.961119Z","iopub.status.idle":"2025-01-27T21:05:51.982206Z","shell.execute_reply.started":"2025-01-27T21:05:51.961088Z","shell.execute_reply":"2025-01-27T21:05:51.981657Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Model validation \ndef validate_model(model, val_loader, device):\n    model.eval()\n    val_loss = 0\n    correct_val = 0\n    total_val = 0\n    all_predictions = []\n    all_true_labels = []\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n            val_loss += outputs.loss.item()\n            predictions = torch.argmax(outputs.logits, dim=-1)\n            all_predictions.extend(predictions.cpu().numpy())\n            all_true_labels.extend(batch['labels'].cpu().numpy())\n            correct_val += (predictions == batch['labels']).sum().item()\n            total_val += batch['labels'].size(0)\n    average_val_loss = val_loss / len(val_loader)\n    accuracy = correct_val / total_val\n    return average_val_loss, accuracy, all_predictions, all_true_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:51.982837Z","iopub.execute_input":"2025-01-27T21:05:51.983037Z","iopub.status.idle":"2025-01-27T21:05:52.000391Z","shell.execute_reply.started":"2025-01-27T21:05:51.983020Z","shell.execute_reply":"2025-01-27T21:05:51.999848Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Hyperparam tune\ndef objective(trial):\n    datasets = [df1_dataset, df2_dataset, df3_dataset, df4_dataset, df5_dataset]\n    balanced_datasets = [df_balanced1_dataset, df_balanced2_dataset, df_balanced3_dataset, df_balanced4_dataset, df_balanced5_dataset]\n\n    # Suggest hyperparameters\n    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n    num_trainable_layers = trial.suggest_int('num_trainable_layers', 1, 6)\n    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n    epochs = trial.suggest_int('epochs', 2, 10)  # Optimizing number of epochs\n    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n    step_size = trial.suggest_int('step_size', 1, 10)\n    gamma = trial.suggest_float('gamma', 0.1, 0.9)\n    pruning_rate = trial.suggest_float('pruning_rate', 0.01, 0.1)\n    grad_clip = 1.0  # If you decide to optimize, add as a trial suggestion\n\n    # Early stopping criteria\n    patience = 3\n    min_delta = 0.001\n    best_val_accuracy = 0\n    no_improve_epochs = 0\n\n    dataset_indices = list(range(5))  # Assuming there are five datasets\n    random.shuffle(dataset_indices)  # Shuffle to randomize which datasets are used for training/validation\n    val_index = dataset_indices.pop()  # Remove one index to use as validation\n    train_indices = dataset_indices  # Use remaining indices for training\n\n    # Load datasets based on shuffled indices\n    train_datasets = [balanced_datasets[i] for i in train_indices]\n    train_combined = torch.utils.data.ConcatDataset(train_datasets)  # Combine datasets for training\n    val_dataset = datasets[val_index]  # Use the corresponding unbalanced dataset for validation\n\n    train_loader = DataLoader(train_combined, batch_size=trial.suggest_categorical('batch_size', [16, 32, 64]), shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=trial.suggest_categorical('batch_size', [16, 32, 64]), shuffle=False)\n\n    # Model setup and modification\n    model_config = DistilBertConfig.from_pretrained('distilbert-base-uncased', num_labels=8)\n    model = DistilBertForSequenceClassification(model_config)\n    model = modify_model(model, num_trainable_layers, dropout_rate, pruning_rate)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    # Optimizer and scheduler\n    optimizer = AdamW(model.parameters(), lr=learning_rate)\n    scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n\n    # Training and validation\n    # train_loader = DataLoader(train1234_dataset, batch_size=batch_size, shuffle=True)\n    # val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    \n    # val_accuracies = []\n    # for epoch in range(epochs):\n    #     train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, GRAD_CLIP, device)\n    #     val_loss, val_accuracy, all_predictions, all_true_labels = validate_model(model, val_loader, device)\n    #     scheduler.step()\n\n    #     # Collect metrics\n    #     val_accuracies.append(val_accuracy)\n\n    for epoch in range(epochs):\n        train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, grad_clip, device)\n        val_loss, val_accuracy, _, _ = validate_model(model, val_loader, device)\n        scheduler.step()\n\n        if val_accuracy > best_val_accuracy + min_delta:\n            best_val_accuracy = val_accuracy\n            no_improve_epochs = 0\n        else:\n            no_improve_epochs += 1\n\n        if no_improve_epochs >= patience:\n            print(f\"Stopping early at epoch {epoch+1}\")\n            break\n\n    file_path = f\"/kaggle/working/output_{trial.number}.pth\"\n    torch.save(model.state_dict(), file_path)\n\n    # Store the best or last validation accuracy\n    # best_val_accuracy = max(val_accuracies)  # or you could use val_accuracies[-1] for the last\n\n    return best_val_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:52.001115Z","iopub.execute_input":"2025-01-27T21:05:52.001348Z","iopub.status.idle":"2025-01-27T21:05:52.023942Z","shell.execute_reply.started":"2025-01-27T21:05:52.001327Z","shell.execute_reply":"2025-01-27T21:05:52.023323Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\n\nstudy.enqueue_trial({\n    'learning_rate': 8.300432875328772e-05,\n    'num_trainable_layers': 2,\n    'dropout_rate': 0.3847406475130443,\n    'batch_size': 32,\n    'step_size': 9,\n    'gamma': 0.5951936405857416,\n    'epochs': 5\n})\n\nstudy.optimize(objective, n_trials=40)  # Adjust the number of trials as needed\n\nprint(\"Best trial:\")\nprint(study.best_trial.params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:05:52.024647Z","iopub.execute_input":"2025-01-27T21:05:52.024829Z","execution_failed":"2025-01-27T21:08:04.220Z"}},"outputs":[{"name":"stderr","text":"[I 2025-01-27 21:05:52,040] A new study created in memory with name: no-name-de76db8f-2f77-4660-937b-cdf22cb53289\n<ipython-input-10-2d9dfced9ac1>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"For comparism, run the below on augmented data. ","metadata":{}},{"cell_type":"code","source":"# def objective1(trial):\n#     # Suggest hyperparameters\n#     learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n#     num_trainable_layers = trial.suggest_int('num_trainable_layers', 1, 6)\n#     dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n#     batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n#     step_size = trial.suggest_int('step_size', 1, 10)\n#     gamma = trial.suggest_float('gamma', 0.1, 0.9)\n#     epochs = trial.suggest_int('epochs', 2, 5)  # Allowing optimization of number of epochs\n\n#     # Model setup and modification\n#     model_config = DistilBertConfig.from_pretrained('distilbert-base-uncased', num_labels=8)\n#     model = DistilBertForSequenceClassification(model_config)\n#     model = modify_model(model, num_trainable_layers, dropout_rate)\n#     model.to(device)\n\n#     # Optimizer and scheduler\n#     optimizer = AdamW(model.parameters(), lr=learning_rate)\n#     scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n\n#     # Training and validation\n#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n#     val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    \n#     val_accuracies = []\n#     for epoch in range(epochs):\n#         train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, device)\n#         val_loss, val_accuracy, all_predictions, all_true_labels = validate_model(model, val_loader, device)\n#         scheduler.step()\n\n#         # Collect metrics\n#         val_accuracies.append(val_accuracy)\n\n#     file_path = f\"/kaggle/working/output1_{trial.number}.pth\"\n#     torch.save(model.state_dict(), file_path)\n\n#     # Store the best or last validation accuracy\n#     best_val_accuracy = max(val_accuracies)  # or you could use val_accuracies[-1] for the last\n\n#     return best_val_accuracy","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T21:08:04.220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# study1 = optuna.create_study(direction='maximize')\n# study1.optimize(objective1, n_trials=50)  # Adjust the number of trials as needed\n\n# print(\"Best trial:\")\n# print(study1.best_trial.params)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T21:08:04.220Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Run the blow code once have best hyperparams ","metadata":{}},{"cell_type":"code","source":"# store this in csv. Try not to re-run the code above. \n# study.best_trial.params","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T21:08:04.220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training params\n# MAX_LENGTH = 365\n\n\n# TRAIN_BATCH_SIZE = 16\n# VAL_BATCH_SIZE = 64\n# LEARNING_RATE = 1e-5\n# STEP_SIZE = 2\n# GAMMA = 0.1\n# EPOCHS = 2","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T21:08:04.220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=8)\n# model.to(device)\n# optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n# scheduler = lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T21:08:04.220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Plotting function for accuracy\n# def plot_accuracies(training_accuracies, validation_accuracies):\n#     plt.figure(figsize=(8, 6))\n#     plt.plot(training_accuracies, label='Training Accuracy')\n#     plt.plot(validation_accuracies, label='Validation Accuracy')\n#     plt.title('Training and Validation Accuracy')\n#     plt.xlabel('Epoch')\n#     plt.ylabel('Accuracy')\n#     plt.legend()\n#     plt.savefig(f\"{output_dir}/accuracy_plot.png\")\n#     plt.close()\n\n# def plot_confusion_matrix(cm, class_labels, epoch, output_dir):\n#     plt.figure(figsize=(10, 8))\n#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n#     plt.title(f'Confusion Matrix for Epoch {epoch + 1}')\n#     plt.ylabel('True Label')\n#     plt.xlabel('Predicted Label')\n#     plt.savefig(os.path.join(output_dir, f'confusion_matrix_epoch_{epoch + 1}.png'))\n#     plt.close()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T21:08:04.220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Training and validation loop\n# train_losses = []\n# val_losses = []\n# train_accuracies = []\n# val_accuracies = []\n# metrics_df = pd.DataFrame()\n\n# for epoch in range(EPOCHS):\n#     model.train()\n#     train_loss = 0\n#     correct_train = 0\n#     total_train = 0\n\n#     for batch in train_loader:\n#         optimizer.zero_grad()\n#         batch = {k: v.to(device) for k, v in batch.items()}\n#         outputs = model(**batch)\n#         loss = outputs.loss\n#         loss.backward()\n#         optimizer.step()\n#         train_loss += loss.item()\n\n#         predictions = torch.argmax(outputs.logits, dim=-1)\n#         correct_train += (predictions == batch['labels']).sum().item()\n#         total_train += batch['labels'].size(0)\n\n#     scheduler.step()\n#     train_losses.append(train_loss / len(train_loader))\n#     train_accuracies.append(correct_train / total_train)\n\n#     model.eval()\n#     val_loss = 0\n#     correct_val = 0\n#     total_val = 0\n#     all_predictions, all_true_labels = [], []\n\n#     with torch.no_grad():\n#         for batch in val_loader:\n#             batch = {k: v.to(device) for k, v in batch.items()}\n#             outputs = model(**batch)\n#             val_loss += outputs.loss.item()\n#             predictions = torch.argmax(outputs.logits, dim=-1)\n#             all_predictions.extend(predictions.cpu().numpy())\n#             all_true_labels.extend(batch['labels'].cpu().numpy())\n\n#             correct_val += (predictions == batch['labels']).sum().item()\n#             total_val += batch['labels'].size(0)\n\n#     val_losses.append(val_loss / len(val_loader))\n#     val_accuracies.append(correct_val / total_val)\n\n#     # Compute confusion matrix\n#     cm = confusion_matrix(all_true_labels, all_predictions)\n#     class_labels = [label_dict.get(i, f'Class {i}') for i in range(len(np.unique(all_true_labels)))]\n#     plot_confusion_matrix(cm, class_labels, epoch, output_dir)\n\n#     # Calculate metrics\n#     balanced_acc = balanced_accuracy_score(all_true_labels, all_predictions)\n#     average_f1 = f1_score(all_true_labels, all_predictions, average='macro')\n#     weighted_f1 = f1_score(all_true_labels, all_predictions, average='weighted')\n#     f1_scores_per_class = f1_score(all_true_labels, all_predictions, average=None)\n#     precision_per_class = precision_score(all_true_labels, all_predictions, average=None, zero_division=0)\n#     recall_per_class = recall_score(all_true_labels, all_predictions, average=None, zero_division=0)\n\n#     # Append metrics to DataFrame with class labels\n#     epoch_metrics = {\n#         \"Epoch\": epoch + 1,\n#         \"Train Loss\": train_losses[-1],\n#         \"Validation Loss\": val_losses[-1],\n#         \"Train Accuracy\": train_accuracies[-1],\n#         \"Validation Accuracy\": val_accuracies[-1],\n#         \"Balanced Accuracy\": balanced_acc,\n#         \"Average F1\": average_f1,\n#         \"Weighted F1\": weighted_f1\n#     }\n#     epoch_metrics.update({f\"{label_dict[i]} F1\": f1_scores_per_class[i] for i in range(len(f1_scores_per_class))})\n#     epoch_metrics.update({f\"{label_dict[i]} Precision\": precision_per_class[i] for i in range(len(precision_per_class))})\n#     epoch_metrics.update({f\"{label_dict[i]} Recall\": recall_per_class[i] for i in range(len(recall_per_class))})\n\n#     metrics_df = pd.concat([metrics_df, pd.DataFrame([epoch_metrics])], ignore_index=True)\n\n# # Save metrics to CSV and plot accuracies\n# metrics_df.to_csv(f\"{output_dir}/training_metrics.csv\", index=False)\n# plot_accuracies(train_accuracies, val_accuracies)\n\n# # Print overall model accuracy\n# overall_accuracy = accuracy_score(y_test, all_predictions)\n# print(f\"Overall Model Accuracy: {overall_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T21:08:04.220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def zip_directory(folder_path, output_path):\n#     \"\"\"Zip the contents of an entire directory and save the archive to the specified output path.\"\"\"\n#     with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n#         for root, dirs, files in os.walk(folder_path):\n#             for file in files:\n#                 # Create a relative path for files to preserve the directory structure\n#                 zipf.write(os.path.join(root, file),\n#                            os.path.relpath(os.path.join(root, file),\n#                                            os.path.join(folder_path, '..')))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T21:08:04.220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Directory to be zipped\n# input_dir = '/kaggle/working/output'\n\n# # Output path for the zip file\n# zip_file_path = '/kaggle/working/output.zip'\n\n# # Creating the ZIP file\n# zip_directory(input_dir, zip_file_path)\n\n# print(f\"Created zip file at: {zip_file_path}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T21:08:04.220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# study = optuna.create_study(direction='minimize')\n# study.optimize(objective, n_trials=20)  # Adjust the number of trials as needed\n\n# print(\"Best trial:\")\n# print(study.best_trial.params)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T21:08:04.220Z"}},"outputs":[],"execution_count":null}]}