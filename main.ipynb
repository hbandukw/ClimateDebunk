{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added the following:\n",
    "\n",
    "| **Strategy**                     | **Purpose**                                                                                      | **Impact on Model**                                                                                     |\n",
    "|----------------------------------|--------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|\n",
    "| **Gradient Clipping**            | Stabilizes training by capping gradients.                                                       | Prevents exploding gradients, ensuring smooth convergence.                                              |\n",
    "| **Learning Rate Scheduler**      | Gradually reduces learning rate during training.                                                 | Enables fine-tuning and prevents overshooting.                                                         |\n",
    "| **Early Stopping**               | Stops training when validation loss stops improving.                                             | Prevents overfitting and saves computational resources.                                                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from sklearn.metrics import f1_score, confusion_matrix, balanced_accuracy_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = \"/kaggle/working/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_parquet(\"/kaggle/input/climatetext/train.parquet\")\n",
    "df['label_int'] = df['label'].str.split(\"_\").str[0].astype('int')\n",
    "\n",
    "# Create dictionary for label names\n",
    "label_dict = df[['label_int', 'label']].drop_duplicates().set_index('label_int')['label'].to_dict()\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=8)\n",
    "\n",
    "# Dataset and DataLoader preparation\n",
    "class QuotesDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def encode_data(tokenizer, texts, labels, max_length):\n",
    "    encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n",
    "    return QuotesDataset(encodings, labels)\n",
    "\n",
    "# Training params\n",
    "MAX_LENGTH = 365\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VAL_BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-5\n",
    "STEP_SIZE = 2\n",
    "GAMMA = 0.1\n",
    "EPOCHS = 10\n",
    "GRAD_CLIP = 1.0  # Gradient clipping value\n",
    "PATIENCE = 3  # early stopping: Number of epochs to wait for improvement\n",
    "MIN_DELTA = 0.01 # early stopping: Minimum loss improvement required\n",
    "\n",
    "# Initialize early stopping parameters\n",
    "best_val_loss = float('inf')  # Track the best validation loss\n",
    "no_improvement_count = 0  # Counter for epochs with no improvement\n",
    "\n",
    "# Split data\n",
    "texts = df[\"quote\"].to_list()\n",
    "labels = df[\"label_int\"].to_list()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "train_dataset = encode_data(tokenizer, X_train, y_train, MAX_LENGTH)\n",
    "val_dataset = encode_data(tokenizer, X_val, y_val, MAX_LENGTH)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "# Plotting functions\n",
    "def plot_accuracies(training_accuracies, validation_accuracies):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(training_accuracies, label='Training Accuracy')\n",
    "    plt.plot(validation_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{output_dir}/accuracy_plot.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(cm, class_labels, epoch, output_dir):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.title(f'Confusion Matrix for Epoch {epoch + 1}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(os.path.join(output_dir, f'confusion_matrix_epoch_{epoch + 1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Function to track GPU power (requires NVIDIA GPU and nvidia-smi)\n",
    "def get_gpu_power():\n",
    "    try:\n",
    "        result = subprocess.check_output(\n",
    "            \"nvidia-smi --query-gpu=power.draw --format=csv,noheader,nounits\",\n",
    "            shell=True\n",
    "        )\n",
    "        power_values = [float(p.strip()) for p in result.decode('utf-8').split('\\n') if p.strip()]\n",
    "        return sum(power_values) / len(power_values)  # Average power in watts\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching GPU power usage: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Training and validation loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        correct_train += (predictions == batch['labels']).sum().item()\n",
    "        total_train += batch['labels'].size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(correct_train / total_train)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_predictions, all_true_labels = [] , []\n",
    "    total_gpu_power = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch_gpu_power = get_gpu_power()  # Track GPU power for each batch\n",
    "            total_gpu_power += batch_gpu_power\n",
    "            batch_count += 1\n",
    "\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_true_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "            correct_val += (predictions == batch['labels']).sum().item()\n",
    "            total_val += batch['labels'].size(0)\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accuracies.append(correct_val / total_val)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_true_labels, all_predictions)\n",
    "    class_labels = [label_dict.get(i, f'Class {i}') for i in range(len(np.unique(all_true_labels)))]\n",
    "    plot_confusion_matrix(cm, class_labels, epoch, output_dir)\n",
    "\n",
    "    # Track energy consumption during validation\n",
    "    avg_gpu_power = total_gpu_power / batch_count if batch_count > 0 else 0\n",
    "    duration_seconds = len(val_loader) * (1 / len(val_loader))  # Approximate time per batch\n",
    "    duration_hours = duration_seconds / 3600.0\n",
    "    energy_kwh = (avg_gpu_power * duration_hours) / 1000.0\n",
    "\n",
    "    print(f\"Validation Energy Consumption: {energy_kwh:.4f} kWh\")\n",
    "    print(f\"Validation Average GPU Power: {avg_gpu_power:.2f} watts\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if (best_val_loss - val_loss) > MIN_DELTA:  # Significant improvement\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_count = 0\n",
    "    else:  # No significant improvement\n",
    "        no_improvement_count += 1\n",
    "        if no_improvement_count >= PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    # Calculate metrics\n",
    "    balanced_acc = balanced_accuracy_score(all_true_labels, all_predictions)\n",
    "    average_f1 = f1_score(all_true_labels, all_predictions, average='macro')\n",
    "    weighted_f1 = f1_score(all_true_labels, all_predictions, average='weighted')\n",
    "    f1_scores_per_class = f1_score(all_true_labels, all_predictions, average=None)\n",
    "    precision_per_class = precision_score(all_true_labels, all_predictions, average=None, zero_division=0)\n",
    "    recall_per_class = recall_score(all_true_labels, all_predictions, average=None, zero_division=0)\n",
    "\n",
    "    # Append metrics to DataFrame with class labels\n",
    "    epoch_metrics = {\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Train Loss\": train_losses[-1],\n",
    "        \"Validation Loss\": val_losses[-1],\n",
    "        \"Train Accuracy\": train_accuracies[-1],\n",
    "        \"Validation Accuracy\": val_accuracies[-1],\n",
    "        \"Balanced Accuracy\": balanced_acc,\n",
    "        \"Average F1\": average_f1,\n",
    "        \"Weighted F1\": weighted_f1,\n",
    "        \"Energy Consumption (kWh)\": energy_kwh,\n",
    "        \"Average GPU Power (Watts)\": avg_gpu_power\n",
    "    }\n",
    "    epoch_metrics.update({f\"{label_dict[i]} F1\": f1_scores_per_class[i] for i in range(len(f1_scores_per_class))})\n",
    "    epoch_metrics.update({f\"{label_dict[i]} Precision\": precision_per_class[i] for i in range(len(precision_per_class))})\n",
    "    epoch_metrics.update({f\"{label_dict[i]} Recall\": recall_per_class[i] for i in range(len(recall_per_class))})\n",
    "\n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame([epoch_metrics])], ignore_index=True)\n",
    "\n",
    "# Save metrics to CSV and plot accuracies\n",
    "metrics_df.to_csv(f\"{output_dir}/training_metrics.csv\", index=False)\n",
    "plot_accuracies(train_accuracies, val_accuracies)\n",
    "\n",
    "# Calculate final model accuracy\n",
    "final_accuracy = accuracy_score(all_true_labels, all_predictions)\n",
    "print(f\"Final Model Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model_path = f\"{output_dir}/trained_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "def zip_directory(folder_path, output_path):\n",
    "    \"\"\"Zip the contents of an entire directory and save the archive to the specified output path.\"\"\"\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # Create a relative path for files to preserve the directory structure\n",
    "                zipf.write(os.path.join(root, file),\n",
    "                           os.path.relpath(os.path.join(root, file),\n",
    "                                           os.path.join(folder_path, '..')))\n",
    "\n",
    "# Directory to be zipped\n",
    "input_dir = '/kaggle/working/output'\n",
    "\n",
    "# Output path for the zip file\n",
    "zip_file_path = '/kaggle/working/output.zip'\n",
    "\n",
    "# Creating the ZIP file\n",
    "zip_directory(input_dir, zip_file_path)\n",
    "\n",
    "print(f\"Created zip file at: {zip_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with best hyperparams\n",
    "\n",
    "Trial 21 finished with value: 0.8999179655455292 and parameters: {'learning_rate': 0.0001932713713098696, 'num_trainable_layers': 1, 'dropout_rate': 0.4517023694187439, 'batch_size': 32, 'step_size': 8, 'gamma': 0.7710877288358753, 'epochs': 5}. Best is trial 21 with value: 0.8999179655455292."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertConfig\n",
    "from sklearn.metrics import f1_score, confusion_matrix, balanced_accuracy_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "# Training params\n",
    "MAX_LENGTH = 365\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VAL_BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001932713713098696\n",
    "STEP_SIZE = 8\n",
    "GAMMA = 0.7710877288358753\n",
    "EPOCHS = 5\n",
    "#GRAD_CLIP = 1.0  # Gradient clipping value\n",
    "#PATIENCE = 3  # early stopping: Number of epochs to wait for improvement\n",
    "#MIN_DELTA = 0.01 # early stopping: Minimum loss improvement required\n",
    "DROPOUT_RATE = 0.4517023694187439\n",
    "NUM_TRAINABLE_LAYERS = 1\n",
    "\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = \"/kaggle/working/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_parquet(\"/kaggle/input/climatetext/train.parquet\")\n",
    "df['label_int'] = df['label'].str.split(\"_\").str[0].astype('int')\n",
    "\n",
    "# Create dictionary for label names\n",
    "label_dict = df[['label_int', 'label']].drop_duplicates().set_index('label_int')['label'].to_dict()\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Initialize model configuration with custom dropout rate\n",
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased', \n",
    "                                          num_labels=8, \n",
    "                                          dropout=DROPOUT_RATE,\n",
    "                                          attention_dropout=DROPOUT_RATE)\n",
    "\n",
    "# Load the model with the updated configuration\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
    "\n",
    "# Freeze all layers except the last `num_trainable_layers`\n",
    "for name, param in model.distilbert.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the last `num_trainable_layers`\n",
    "for layer_idx in range(6 - NUM_TRAINABLE_LAYERS, 6):  # DistilBERT has 6 layers\n",
    "    for name, param in model.distilbert.transformer.layer[layer_idx].named_parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Ensure classification head is trainable\n",
    "for name, param in model.classifier.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "#model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=8)\n",
    "\n",
    "# Dataset and DataLoader preparation\n",
    "class QuotesDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def encode_data(tokenizer, texts, labels, max_length):\n",
    "    encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n",
    "    return QuotesDataset(encodings, labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize early stopping parameters\n",
    "#best_val_loss = float('inf')  # Track the best validation loss\n",
    "#no_improvement_count = 0  # Counter for epochs with no improvement\n",
    "\n",
    "# Split data\n",
    "texts = df[\"quote\"].to_list()\n",
    "labels = df[\"label_int\"].to_list()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "train_dataset = encode_data(tokenizer, X_train, y_train, MAX_LENGTH)\n",
    "val_dataset = encode_data(tokenizer, X_val, y_val, MAX_LENGTH)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "# Plotting functions\n",
    "def plot_accuracies(training_accuracies, validation_accuracies):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(training_accuracies, label='Training Accuracy')\n",
    "    plt.plot(validation_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{output_dir}/accuracy_plot.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(cm, class_labels, epoch, output_dir):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.title(f'Confusion Matrix for Epoch {epoch + 1}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(os.path.join(output_dir, f'confusion_matrix_epoch_{epoch + 1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Function to track GPU power (requires NVIDIA GPU and nvidia-smi)\n",
    "#def get_gpu_power():\n",
    "#    try:\n",
    "#        result = subprocess.check_output(\n",
    "#           \"nvidia-smi --query-gpu=power.draw --format=csv,noheader,nounits\",\n",
    "#            shell=True\n",
    "#        )\n",
    "#        power_values = [float(p.strip()) for p in result.decode('utf-8').split('\\n') if p.strip()]\n",
    "#        return sum(power_values) / len(power_values)  # Average power in watts\n",
    "#    except Exception as e:\n",
    "#        print(f\"Error fetching GPU power usage: {e}\")\n",
    "#       return 0\n",
    "\n",
    "# Training and validation loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "\n",
    "        optimizer.step()  \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        correct_train += (predictions == batch['labels']).sum().item()\n",
    "        total_train += batch['labels'].size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(correct_train / total_train)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_predictions, all_true_labels = [] , []\n",
    "    total_gpu_power = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            #batch_gpu_power = get_gpu_power()  # Track GPU power for each batch\n",
    "            #total_gpu_power += batch_gpu_power\n",
    "            #batch_count += 1\n",
    "\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_true_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "            correct_val += (predictions == batch['labels']).sum().item()\n",
    "            total_val += batch['labels'].size(0)\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accuracies.append(correct_val / total_val)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_true_labels, all_predictions)\n",
    "    class_labels = [label_dict.get(i, f'Class {i}') for i in range(len(np.unique(all_true_labels)))]\n",
    "    plot_confusion_matrix(cm, class_labels, epoch, output_dir)\n",
    "\n",
    "    # Track energy consumption during validation\n",
    "    #avg_gpu_power = total_gpu_power / batch_count if batch_count > 0 else 0\n",
    "    #duration_seconds = len(val_loader) * (1 / len(val_loader))  # Approximate time per batch\n",
    "    #duration_hours = duration_seconds / 3600.0\n",
    "    #energy_kwh = (avg_gpu_power * duration_hours) / 1000.0\n",
    "\n",
    "    #print(f\"Validation Energy Consumption: {energy_kwh:.4f} kWh\")\n",
    "    #print(f\"Validation Average GPU Power: {avg_gpu_power:.2f} watts\")\n",
    "\n",
    "    # Early stopping check\n",
    "    #if (best_val_loss - val_loss) > MIN_DELTA:  # Significant improvement\n",
    "    #    best_val_loss = val_loss\n",
    "    #    no_improvement_count = 0\n",
    "    #else:  # No significant improvement\n",
    "    #   no_improvement_count += 1\n",
    "    #    if no_improvement_count >= PATIENCE:\n",
    "    #        print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "    #        break\n",
    "\n",
    "    # Calculate metrics\n",
    "    balanced_acc = balanced_accuracy_score(all_true_labels, all_predictions)\n",
    "    average_f1 = f1_score(all_true_labels, all_predictions, average='macro')\n",
    "    weighted_f1 = f1_score(all_true_labels, all_predictions, average='weighted')\n",
    "    f1_scores_per_class = f1_score(all_true_labels, all_predictions, average=None)\n",
    "    precision_per_class = precision_score(all_true_labels, all_predictions, average=None, zero_division=0)\n",
    "    recall_per_class = recall_score(all_true_labels, all_predictions, average=None, zero_division=0)\n",
    "\n",
    "    # Append metrics to DataFrame with class labels\n",
    "    epoch_metrics = {\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Train Loss\": train_losses[-1],\n",
    "        \"Validation Loss\": val_losses[-1],\n",
    "        \"Train Accuracy\": train_accuracies[-1],\n",
    "        \"Validation Accuracy\": val_accuracies[-1],\n",
    "        \"Balanced Accuracy\": balanced_acc,\n",
    "        \"Average F1\": average_f1,\n",
    "        \"Weighted F1\": weighted_f1,\n",
    "        #\"Energy Consumption (kWh)\": energy_kwh,\n",
    "        #\"Average GPU Power (Watts)\": avg_gpu_power\n",
    "    }\n",
    "    epoch_metrics.update({f\"{label_dict[i]} F1\": f1_scores_per_class[i] for i in range(len(f1_scores_per_class))})\n",
    "    epoch_metrics.update({f\"{label_dict[i]} Precision\": precision_per_class[i] for i in range(len(precision_per_class))})\n",
    "    epoch_metrics.update({f\"{label_dict[i]} Recall\": recall_per_class[i] for i in range(len(recall_per_class))})\n",
    "\n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame([epoch_metrics])], ignore_index=True)\n",
    "\n",
    "# Save metrics to CSV and plot accuracies\n",
    "metrics_df.to_csv(f\"{output_dir}/training_metrics.csv\", index=False)\n",
    "plot_accuracies(train_accuracies, val_accuracies)\n",
    "\n",
    "# Calculate final model accuracy\n",
    "final_accuracy = accuracy_score(all_true_labels, all_predictions)\n",
    "print(f\"Final Model Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model_path = f\"{output_dir}/trained_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
