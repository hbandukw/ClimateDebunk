{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10471355,"sourceType":"datasetVersion","datasetId":6483657}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install nlpaug","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:38.379564Z","iopub.execute_input":"2025-01-20T18:38:38.379845Z","iopub.status.idle":"2025-01-20T18:38:42.936222Z","shell.execute_reply.started":"2025-01-20T18:38:38.379823Z","shell.execute_reply":"2025-01-20T18:38:42.935127Z"}},"outputs":[{"name":"stdout","text":"Collecting nlpaug\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.26.4)\nRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.2.2)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.32.3)\nRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.16.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.12.14)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.6)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.2->nlpaug) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nlpaug\nSuccessfully installed nlpaug-1.1.11\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport re\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\nimport nlpaug.augmenter.word as naw","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:39:37.744207Z","iopub.execute_input":"2025-01-20T18:39:37.744678Z","iopub.status.idle":"2025-01-20T18:40:05.741387Z","shell.execute_reply.started":"2025-01-20T18:39:37.744636Z","shell.execute_reply":"2025-01-20T18:40:05.740651Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:40:08.020164Z","iopub.execute_input":"2025-01-20T18:40:08.020776Z","iopub.status.idle":"2025-01-20T18:40:08.024702Z","shell.execute_reply.started":"2025-01-20T18:40:08.020750Z","shell.execute_reply":"2025-01-20T18:40:08.023737Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def extract_number(label):\n    match = re.match(r'(\\d+)_', label)\n    if match:\n        return int(match.group(1))  \n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:40:10.163500Z","iopub.execute_input":"2025-01-20T18:40:10.163792Z","iopub.status.idle":"2025-01-20T18:40:10.167830Z","shell.execute_reply.started":"2025-01-20T18:40:10.163771Z","shell.execute_reply":"2025-01-20T18:40:10.167005Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = pd.read_parquet('/kaggle/input/train-parquet/train.parquet')\ndf['numeric_label'] = df['label'].apply(extract_number)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:43:09.654504Z","iopub.execute_input":"2025-01-20T18:43:09.654831Z","iopub.status.idle":"2025-01-20T18:43:09.847565Z","shell.execute_reply.started":"2025-01-20T18:43:09.654799Z","shell.execute_reply":"2025-01-20T18:43:09.846864Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train, test = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:43:13.502125Z","iopub.execute_input":"2025-01-20T18:43:13.502466Z","iopub.status.idle":"2025-01-20T18:43:13.513591Z","shell.execute_reply.started":"2025-01-20T18:43:13.502439Z","shell.execute_reply":"2025-01-20T18:43:13.512692Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"num_rows = len(train)\nfirst_quarter = int(num_rows * 0.25)\nsecond_quarter = int(num_rows * 0.50)\nthird_quarter = int(num_rows * 0.75)\n\n# Get the first 25% of the rows\ntrain1 = train.iloc[:first_quarter]\n\n# Get the second 25% of the rows\ntrain2 = train.iloc[first_quarter:second_quarter]\n\n# Get the third 25% of the rows\ntrain3 = train.iloc[second_quarter:third_quarter]\n\n# Get the last 25% of the rows\ntrain4 = train.iloc[third_quarter:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:43:17.780896Z","iopub.execute_input":"2025-01-20T18:43:17.781271Z","iopub.status.idle":"2025-01-20T18:43:17.786978Z","shell.execute_reply.started":"2025-01-20T18:43:17.781244Z","shell.execute_reply":"2025-01-20T18:43:17.785822Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:43:20.679883Z","iopub.execute_input":"2025-01-20T18:43:20.680342Z","iopub.status.idle":"2025-01-20T18:43:20.770775Z","shell.execute_reply.started":"2025-01-20T18:43:20.680305Z","shell.execute_reply":"2025-01-20T18:43:20.769670Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"aug = naw.ContextualWordEmbsAug(\n    model_path='bert-base-uncased',\n    action='substitute',\n    device='cuda' if torch.cuda.is_available() else 'cpu'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:43:37.213145Z","iopub.execute_input":"2025-01-20T18:43:37.213472Z","iopub.status.idle":"2025-01-20T18:43:41.139143Z","shell.execute_reply.started":"2025-01-20T18:43:37.213448Z","shell.execute_reply":"2025-01-20T18:43:41.138358Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acb9621dac0c4dd68f93f293e8efd545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd32be0b489044e2a66e396d671a2956"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b2b483acedb428f86094acc77fe7d4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43de63c9681e41c08fa51d0109a5bbbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"706e08638f62403bb25494643bd32c59"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"class_counts1 = train1['numeric_label'].value_counts()\nmax_count1 = class_counts1.max()\naugment_counts1 = max_count1 - class_counts1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:47:27.359847Z","iopub.execute_input":"2025-01-20T18:47:27.360202Z","iopub.status.idle":"2025-01-20T18:47:27.371951Z","shell.execute_reply.started":"2025-01-20T18:47:27.360176Z","shell.execute_reply":"2025-01-20T18:47:27.371182Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"augmented_rows1 = []\n\n# Perform augmentation for underrepresented classes\nfor label, deficit in augment_counts1.items():\n    if deficit > 0:\n        # Sample from the existing rows of the class\n        sample_rows = train1[train1['numeric_label'] == label].sample(n=deficit, replace=True)\n        for _, row in sample_rows.iterrows():\n            augmented_text = aug.augment(row['quote'])\n            # Create a new row with the augmented text and same label\n            augmented_rows1.append([augmented_text, label, row['source'], row['url'], row['language'], row['subsource'], row['id']])\n\n# Create a DataFrame from the augmented rows\naugmented_df1 = pd.DataFrame(augmented_rows1, columns=['quote', 'numeric_label', 'source', 'url', 'language', 'subsource', 'id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:47:43.692603Z","iopub.execute_input":"2025-01-20T18:47:43.692909Z","iopub.status.idle":"2025-01-20T18:50:45.624191Z","shell.execute_reply.started":"2025-01-20T18:47:43.692886Z","shell.execute_reply":"2025-01-20T18:50:45.623199Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"augmented_df_copy1 = augmented_df1.copy()\naugmented_df_copy1['quote'] = augmented_df_copy1['quote'].astype(str)\naugmented_df_copy1['quote'] = augmented_df_copy1['quote'].str.replace(r\"^\\['|'\\]$\", '', regex=True)\ndf_balanced1 = pd.concat([train1, augmented_df_copy1], ignore_index=True)\ndf_balanced1['numeric_label'] = df_balanced1['numeric_label'].astype(int)\ndf_balanced1.to_csv('train1.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:59:54.918800Z","iopub.execute_input":"2025-01-20T18:59:54.919094Z","iopub.status.idle":"2025-01-20T18:59:54.965069Z","shell.execute_reply.started":"2025-01-20T18:59:54.919072Z","shell.execute_reply":"2025-01-20T18:59:54.964337Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class_counts2 = train2['numeric_label'].value_counts()\nmax_count2 = class_counts2.max()\naugment_counts2 = max_count2 - class_counts2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:53:09.090598Z","iopub.execute_input":"2025-01-20T18:53:09.090964Z","iopub.status.idle":"2025-01-20T18:53:09.095967Z","shell.execute_reply.started":"2025-01-20T18:53:09.090936Z","shell.execute_reply":"2025-01-20T18:53:09.095117Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"augmented_rows2 = []\n\n# Perform augmentation for underrepresented classes\nfor label, deficit in augment_counts2.items():\n    if deficit > 0:\n        # Sample from the existing rows of the class\n        sample_rows = train2[train2['numeric_label'] == label].sample(n=deficit, replace=True)\n        for _, row in sample_rows.iterrows():\n            augmented_text = aug.augment(row['quote'])\n            # Create a new row with the augmented text and same label\n            augmented_rows2.append([augmented_text, label, row['source'], row['url'], row['language'], row['subsource'], row['id']])\n\n# Create a DataFrame from the augmented rows\naugmented_df2 = pd.DataFrame(augmented_rows2, columns=['quote', 'numeric_label', 'source', 'url', 'language', 'subsource', 'id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:54:52.208644Z","iopub.execute_input":"2025-01-20T18:54:52.209036Z","iopub.status.idle":"2025-01-20T18:58:39.476719Z","shell.execute_reply.started":"2025-01-20T18:54:52.208994Z","shell.execute_reply":"2025-01-20T18:58:39.476004Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"augmented_df_copy2 = augmented_df2.copy()\naugmented_df_copy2['quote'] = augmented_df_copy2['quote'].astype(str)\naugmented_df_copy2['quote'] = augmented_df_copy2['quote'].str.replace(r\"^\\['|'\\]$\", '', regex=True)\ndf_balanced2 = pd.concat([train2, augmented_df_copy2], ignore_index=True)\ndf_balanced2['numeric_label'] = df_balanced2['numeric_label'].astype(int)\ndf_balanced2.to_csv('train2.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:59:59.905641Z","iopub.execute_input":"2025-01-20T18:59:59.905936Z","iopub.status.idle":"2025-01-20T18:59:59.956007Z","shell.execute_reply.started":"2025-01-20T18:59:59.905914Z","shell.execute_reply":"2025-01-20T18:59:59.955111Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"class_counts3 = train3['numeric_label'].value_counts()\nmax_count3 = class_counts3.max()\naugment_counts3 = max_count3 - class_counts3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T19:00:26.155532Z","iopub.execute_input":"2025-01-20T19:00:26.155864Z","iopub.status.idle":"2025-01-20T19:00:26.160499Z","shell.execute_reply.started":"2025-01-20T19:00:26.155835Z","shell.execute_reply":"2025-01-20T19:00:26.159715Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"augmented_rows3 = []\n\n# Perform augmentation for underrepresented classes\nfor label, deficit in augment_counts3.items():\n    if deficit > 0:\n        # Sample from the existing rows of the class\n        sample_rows = train3[train3['numeric_label'] == label].sample(n=deficit, replace=True)\n        for _, row in sample_rows.iterrows():\n            augmented_text = aug.augment(row['quote'])\n            # Create a new row with the augmented text and same label\n            augmented_rows3.append([augmented_text, label, row['source'], row['url'], row['language'], row['subsource'], row['id']])\n\n# Create a DataFrame from the augmented rows\naugmented_df3 = pd.DataFrame(augmented_rows3, columns=['quote', 'numeric_label', 'source', 'url', 'language', 'subsource', 'id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T19:00:43.808305Z","iopub.execute_input":"2025-01-20T19:00:43.808698Z","iopub.status.idle":"2025-01-20T19:04:31.061376Z","shell.execute_reply.started":"2025-01-20T19:00:43.808666Z","shell.execute_reply":"2025-01-20T19:04:31.060403Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"augmented_df_copy3 = augmented_df3.copy()\naugmented_df_copy3['quote'] = augmented_df_copy3['quote'].astype(str)\naugmented_df_copy3['quote'] = augmented_df_copy3['quote'].str.replace(r\"^\\['|'\\]$\", '', regex=True)\ndf_balanced3 = pd.concat([train2, augmented_df_copy3], ignore_index=True)\ndf_balanced3['numeric_label'] = df_balanced3['numeric_label'].astype(int)\ndf_balanced3.to_csv('train3.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T19:04:39.288093Z","iopub.execute_input":"2025-01-20T19:04:39.288433Z","iopub.status.idle":"2025-01-20T19:04:39.337775Z","shell.execute_reply.started":"2025-01-20T19:04:39.288409Z","shell.execute_reply":"2025-01-20T19:04:39.337115Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"class_counts4 = train4['numeric_label'].value_counts()\nmax_count4 = class_counts4.max()\naugment_counts4 = max_count4 - class_counts4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T19:04:42.996623Z","iopub.execute_input":"2025-01-20T19:04:42.996924Z","iopub.status.idle":"2025-01-20T19:04:43.002209Z","shell.execute_reply.started":"2025-01-20T19:04:42.996900Z","shell.execute_reply":"2025-01-20T19:04:43.001069Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"augmented_rows4 = []\n\n# Perform augmentation for underrepresented classes\nfor label, deficit in augment_counts4.items():\n    if deficit > 0:\n        # Sample from the existing rows of the class\n        sample_rows = train4[train4['numeric_label'] == label].sample(n=deficit, replace=True)\n        for _, row in sample_rows.iterrows():\n            augmented_text = aug.augment(row['quote'])\n            # Create a new row with the augmented text and same label\n            augmented_rows4.append([augmented_text, label, row['source'], row['url'], row['language'], row['subsource'], row['id']])\n\n# Create a DataFrame from the augmented rows\naugmented_df4 = pd.DataFrame(augmented_rows4, columns=['quote', 'numeric_label', 'source', 'url', 'language', 'subsource', 'id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T19:04:48.076663Z","iopub.execute_input":"2025-01-20T19:04:48.076951Z","iopub.status.idle":"2025-01-20T19:09:14.407927Z","shell.execute_reply.started":"2025-01-20T19:04:48.076930Z","shell.execute_reply":"2025-01-20T19:09:14.407187Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"augmented_df_copy4 = augmented_df4.copy()\naugmented_df_copy4['quote'] = augmented_df_copy4['quote'].astype(str)\naugmented_df_copy4['quote'] = augmented_df_copy4['quote'].str.replace(r\"^\\['|'\\]$\", '', regex=True)\ndf_balanced4 = pd.concat([train4, augmented_df_copy4], ignore_index=True)\ndf_balanced4['numeric_label'] = df_balanced4['numeric_label'].astype(int)\ndf_balanced4.to_csv('train4.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T19:09:53.639690Z","iopub.execute_input":"2025-01-20T19:09:53.639992Z","iopub.status.idle":"2025-01-20T19:09:53.696979Z","shell.execute_reply.started":"2025-01-20T19:09:53.639969Z","shell.execute_reply":"2025-01-20T19:09:53.696358Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"test.to_csv('test.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T19:10:52.699011Z","iopub.execute_input":"2025-01-20T19:10:52.699334Z","iopub.status.idle":"2025-01-20T19:10:52.717486Z","shell.execute_reply.started":"2025-01-20T19:10:52.699311Z","shell.execute_reply":"2025-01-20T19:10:52.716632Z"}},"outputs":[],"execution_count":30}]}