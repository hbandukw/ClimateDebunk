{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10471355,"sourceType":"datasetVersion","datasetId":6483657}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install nlpaug","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:08:30.917129Z","iopub.execute_input":"2025-01-19T20:08:30.917317Z","iopub.status.idle":"2025-01-19T20:08:35.852235Z","shell.execute_reply.started":"2025-01-19T20:08:30.917299Z","shell.execute_reply":"2025-01-19T20:08:35.851171Z"}},"outputs":[{"name":"stdout","text":"Collecting nlpaug\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.26.4)\nRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.2.2)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.32.3)\nRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.16.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.12.14)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.6)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.2->nlpaug) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nlpaug\nSuccessfully installed nlpaug-1.1.11\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport re\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\nimport nlpaug.augmenter.word as naw","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:08:51.852033Z","iopub.execute_input":"2025-01-19T20:08:51.852424Z","iopub.status.idle":"2025-01-19T20:09:36.336630Z","shell.execute_reply.started":"2025-01-19T20:08:51.852381Z","shell.execute_reply":"2025-01-19T20:09:36.335997Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:09:38.694153Z","iopub.execute_input":"2025-01-19T20:09:38.694823Z","iopub.status.idle":"2025-01-19T20:09:38.698806Z","shell.execute_reply.started":"2025-01-19T20:09:38.694794Z","shell.execute_reply":"2025-01-19T20:09:38.697848Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def extract_number(label):\n    match = re.match(r'(\\d+)_', label)\n    if match:\n        return int(match.group(1))  \n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:09:40.999890Z","iopub.execute_input":"2025-01-19T20:09:41.000203Z","iopub.status.idle":"2025-01-19T20:09:41.004296Z","shell.execute_reply.started":"2025-01-19T20:09:41.000176Z","shell.execute_reply":"2025-01-19T20:09:41.003276Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"- source of data: https://huggingface.co/datasets/QuotaClimat/frugalaichallenge-text-train","metadata":{}},{"cell_type":"code","source":"df = pd.read_parquet('/kaggle/input/train.parquet')\ndf['numeric_label'] = df['label'].apply(extract_number)\n# print(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:09:47.677856Z","iopub.execute_input":"2025-01-19T20:09:47.678150Z","iopub.status.idle":"2025-01-19T20:09:47.860247Z","shell.execute_reply.started":"2025-01-19T20:09:47.678128Z","shell.execute_reply":"2025-01-19T20:09:47.859581Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# print(df['label'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T23:42:15.231051Z","iopub.execute_input":"2025-01-17T23:42:15.231780Z","iopub.status.idle":"2025-01-17T23:42:15.236133Z","shell.execute_reply.started":"2025-01-17T23:42:15.231749Z","shell.execute_reply":"2025-01-17T23:42:15.234834Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# print(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T23:42:16.687758Z","iopub.execute_input":"2025-01-17T23:42:16.688309Z","iopub.status.idle":"2025-01-17T23:42:16.692421Z","shell.execute_reply.started":"2025-01-17T23:42:16.688267Z","shell.execute_reply":"2025-01-17T23:42:16.691286Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# filtered_df = df[df['numeric_label'] == 0]\n# pd.set_option('display.max_colwidth', None)\n\n# # Display the 'quote' column\n# print(filtered_df['quote'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T23:42:19.233262Z","iopub.execute_input":"2025-01-17T23:42:19.233574Z","iopub.status.idle":"2025-01-17T23:42:19.237339Z","shell.execute_reply.started":"2025-01-17T23:42:19.233545Z","shell.execute_reply":"2025-01-17T23:42:19.236360Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"train, test = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:09:51.295921Z","iopub.execute_input":"2025-01-19T20:09:51.296242Z","iopub.status.idle":"2025-01-19T20:09:51.306264Z","shell.execute_reply.started":"2025-01-19T20:09:51.296212Z","shell.execute_reply":"2025-01-19T20:09:51.305590Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"num_rows = len(train)\nfirst_quarter = int(num_rows * 0.25)\n\n# Get the first 25% of the rows\ntrain1 = train.iloc[:first_quarter]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:09:52.914292Z","iopub.execute_input":"2025-01-19T20:09:52.914578Z","iopub.status.idle":"2025-01-19T20:09:52.918461Z","shell.execute_reply.started":"2025-01-19T20:09:52.914556Z","shell.execute_reply":"2025-01-19T20:09:52.917663Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# train_texts, test_texts, train_labels, test_labels = train_test_split(df['quote'], df['numeric_label'], test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T23:42:45.742347Z","iopub.execute_input":"2025-01-17T23:42:45.742640Z","iopub.status.idle":"2025-01-17T23:42:45.746137Z","shell.execute_reply.started":"2025-01-17T23:42:45.742616Z","shell.execute_reply":"2025-01-17T23:42:45.745224Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:09:55.355433Z","iopub.execute_input":"2025-01-19T20:09:55.355780Z","iopub.status.idle":"2025-01-19T20:09:55.431583Z","shell.execute_reply.started":"2025-01-19T20:09:55.355753Z","shell.execute_reply":"2025-01-19T20:09:55.430735Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"- Distilbert should be less energy consuming, it has less params \n- Lower case so less params ","metadata":{}},{"cell_type":"markdown","source":"**Augmentation**","metadata":{}},{"cell_type":"code","source":"aug = naw.ContextualWordEmbsAug(\n    model_path='bert-base-uncased',\n    action='substitute',\n    device='cuda' if torch.cuda.is_available() else 'cpu'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:09:57.982103Z","iopub.execute_input":"2025-01-19T20:09:57.982395Z","iopub.status.idle":"2025-01-19T20:10:03.360797Z","shell.execute_reply.started":"2025-01-19T20:09:57.982373Z","shell.execute_reply":"2025-01-19T20:10:03.360089Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4869cba2e44c4ac69e0e91340d9919e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211297ffb1554fada75496fe6e50e671"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f502bc38f6041f1bd8867a9120725ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27ea565429b64426a530ad451e224683"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26f65bc36f8049368970d97024867d01"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"class_counts = train1['numeric_label'].value_counts()\n# class_counts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:10:09.671725Z","iopub.execute_input":"2025-01-19T20:10:09.672034Z","iopub.status.idle":"2025-01-19T20:10:09.681427Z","shell.execute_reply.started":"2025-01-19T20:10:09.672011Z","shell.execute_reply":"2025-01-19T20:10:09.680430Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"max_count = class_counts.max()\naugment_counts = max_count - class_counts\n# augment_counts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:10:13.702801Z","iopub.execute_input":"2025-01-19T20:10:13.703085Z","iopub.status.idle":"2025-01-19T20:10:13.708444Z","shell.execute_reply.started":"2025-01-19T20:10:13.703063Z","shell.execute_reply":"2025-01-19T20:10:13.707595Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"below will take a while to run","metadata":{}},{"cell_type":"code","source":"augmented_rows = []\n\n# Perform augmentation for underrepresented classes\nfor label, deficit in augment_counts.items():\n    if deficit > 0:\n        # Sample from the existing rows of the class\n        sample_rows = train1[train1['numeric_label'] == label].sample(n=deficit, replace=True)\n        for _, row in sample_rows.iterrows():\n            augmented_text = aug.augment(row['quote'])\n            # Create a new row with the augmented text and same label\n            augmented_rows.append([augmented_text, label, row['source'], row['url'], row['language'], row['subsource'], row['id']])\n\n# Create a DataFrame from the augmented rows\naugmented_df = pd.DataFrame(augmented_rows, columns=['quote', 'numeric_label', 'source', 'url', 'language', 'subsource', 'id'])\naugmented_df.head() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:10:19.066512Z","iopub.execute_input":"2025-01-19T20:10:19.066826Z","iopub.status.idle":"2025-01-19T20:13:18.564623Z","shell.execute_reply.started":"2025-01-19T20:10:19.066801Z","shell.execute_reply":"2025-01-19T20:13:18.563459Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                               quote  numeric_label  source  \\\n0  [the clean air agenda, by series of decisions ...              4  Desmog   \n1  [america is much more regulated than the uk an...              4  Desmog   \n2  [one to his central building blocks of the ’ w...              4  Desmog   \n3  [whilst my business case for government addres...              4  Desmog   \n4  [the counter - intuitive truth is that to succ...              4  Desmog   \n\n                                                 url language subsource    id  \n0                  https://www.desmog.com/oren-cass/       en      None  None  \n1              https://www.desmog.com/jim-ratcliffe/       en      None  None  \n2  https://www.desmog.com/american-energy-allianc...       en      None  None  \n3             https://www.desmog.com/andrea-leadsom/       en      None  None  \n4               https://www.desmog.com/tim-worstall/       en      None  None  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>quote</th>\n      <th>numeric_label</th>\n      <th>source</th>\n      <th>url</th>\n      <th>language</th>\n      <th>subsource</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[the clean air agenda, by series of decisions ...</td>\n      <td>4</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/oren-cass/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[america is much more regulated than the uk an...</td>\n      <td>4</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/jim-ratcliffe/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[one to his central building blocks of the ’ w...</td>\n      <td>4</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/american-energy-allianc...</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[whilst my business case for government addres...</td>\n      <td>4</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/andrea-leadsom/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[the counter - intuitive truth is that to succ...</td>\n      <td>4</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/tim-worstall/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"Above take long to run, create a copy incase mess up and need rerun ","metadata":{}},{"cell_type":"code","source":"augmented_df_copy = augmented_df.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:13:26.998473Z","iopub.execute_input":"2025-01-19T20:13:26.998867Z","iopub.status.idle":"2025-01-19T20:13:27.003360Z","shell.execute_reply.started":"2025-01-19T20:13:26.998835Z","shell.execute_reply":"2025-01-19T20:13:27.002334Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"augmented_df_copy['quote'] = augmented_df_copy['quote'].astype(str)\naugmented_df_copy['quote'] = augmented_df_copy['quote'].str.replace(r\"^\\['|'\\]$\", '', regex=True)\n\naugmented_df_copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:13:29.638522Z","iopub.execute_input":"2025-01-19T20:13:29.638867Z","iopub.status.idle":"2025-01-19T20:13:29.665272Z","shell.execute_reply.started":"2025-01-19T20:13:29.638839Z","shell.execute_reply":"2025-01-19T20:13:29.664479Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                  quote  numeric_label  \\\n0     the clean air agenda, by series of decisions m...              4   \n1     america is much more regulated than the uk and...              4   \n2     one to his central building blocks of the ’ wi...              4   \n3     whilst my business case for government address...              4   \n4     the counter - intuitive truth is that to succe...              4   \n...                                                 ...            ...   \n1121  energy is the lifeblood our society. it doesn ...              7   \n1122  then if many get ’ better set policy, your sta...              7   \n1123  it is no necessity to export domestic water an...              7   \n1124  so the supply should be increased by hook or c...              7   \n1125  to put a limit on the and the fossil sources f...              7   \n\n      source                                                url language  \\\n0     Desmog                  https://www.desmog.com/oren-cass/       en   \n1     Desmog              https://www.desmog.com/jim-ratcliffe/       en   \n2     Desmog  https://www.desmog.com/american-energy-allianc...       en   \n3     Desmog             https://www.desmog.com/andrea-leadsom/       en   \n4     Desmog               https://www.desmog.com/tim-worstall/       en   \n...      ...                                                ...      ...   \n1121  Desmog             https://www.desmog.com/derrick-hollie/       en   \n1122  Desmog              https://www.desmog.com/bruce-everett/       en   \n1123  Desmog               https://www.desmog.com/peter-lilley/       en   \n1124  Desmog             https://www.desmog.com/vincent-devito/       en   \n1125  Desmog       https://www.desmog.com/deepak-lal-1940-2020/       en   \n\n     subsource    id  \n0         None  None  \n1         None  None  \n2         None  None  \n3         None  None  \n4         None  None  \n...        ...   ...  \n1121      None  None  \n1122      None  None  \n1123      None  None  \n1124      None  None  \n1125      None  None  \n\n[1126 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>quote</th>\n      <th>numeric_label</th>\n      <th>source</th>\n      <th>url</th>\n      <th>language</th>\n      <th>subsource</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the clean air agenda, by series of decisions m...</td>\n      <td>4</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/oren-cass/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>america is much more regulated than the uk and...</td>\n      <td>4</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/jim-ratcliffe/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>one to his central building blocks of the ’ wi...</td>\n      <td>4</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/american-energy-allianc...</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>whilst my business case for government address...</td>\n      <td>4</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/andrea-leadsom/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>the counter - intuitive truth is that to succe...</td>\n      <td>4</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/tim-worstall/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1121</th>\n      <td>energy is the lifeblood our society. it doesn ...</td>\n      <td>7</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/derrick-hollie/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1122</th>\n      <td>then if many get ’ better set policy, your sta...</td>\n      <td>7</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/bruce-everett/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1123</th>\n      <td>it is no necessity to export domestic water an...</td>\n      <td>7</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/peter-lilley/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1124</th>\n      <td>so the supply should be increased by hook or c...</td>\n      <td>7</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/vincent-devito/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1125</th>\n      <td>to put a limit on the and the fossil sources f...</td>\n      <td>7</td>\n      <td>Desmog</td>\n      <td>https://www.desmog.com/deepak-lal-1940-2020/</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>1126 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"df_balanced1 = pd.concat([train1, augmented_df_copy], ignore_index=True)\ndf_balanced1['numeric_label'] = df_balanced1['numeric_label'].astype(int)\n\n# df_balanced1.head() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:13:36.630681Z","iopub.execute_input":"2025-01-19T20:13:36.630992Z","iopub.status.idle":"2025-01-19T20:13:36.637187Z","shell.execute_reply.started":"2025-01-19T20:13:36.630967Z","shell.execute_reply":"2025-01-19T20:13:36.636365Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"Check if matches so does not cause trouble tokenize ","metadata":{}},{"cell_type":"code","source":"# train1.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:13:41.862774Z","iopub.execute_input":"2025-01-19T20:13:41.863060Z","iopub.status.idle":"2025-01-19T20:13:41.866478Z","shell.execute_reply.started":"2025-01-19T20:13:41.863039Z","shell.execute_reply":"2025-01-19T20:13:41.865449Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# df_balanced1.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:13:45.009063Z","iopub.execute_input":"2025-01-19T20:13:45.009352Z","iopub.status.idle":"2025-01-19T20:13:45.012955Z","shell.execute_reply.started":"2025-01-19T20:13:45.009328Z","shell.execute_reply":"2025-01-19T20:13:45.012091Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"check for class balance ","metadata":{}},{"cell_type":"code","source":"print(df_balanced1['numeric_label'].value_counts()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:09.142643Z","iopub.execute_input":"2025-01-19T20:14:09.143002Z","iopub.status.idle":"2025-01-19T20:14:09.149233Z","shell.execute_reply.started":"2025-01-19T20:14:09.142973Z","shell.execute_reply":"2025-01-19T20:14:09.148135Z"}},"outputs":[{"name":"stdout","text":"numeric_label\n0    293\n6    293\n3    293\n2    293\n1    293\n4    293\n5    293\n7    293\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"**split data**","metadata":{}},{"cell_type":"code","source":"train1_texts = train1['quote']\ntrain1_labels = train1['numeric_label']\ndf_balanced1_texts = df_balanced1['quote']\ndf_balanced1_labels = df_balanced1['numeric_label']\ntest_texts = test['quote']\ntest_labels = test['numeric_label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:13.960880Z","iopub.execute_input":"2025-01-19T20:14:13.961187Z","iopub.status.idle":"2025-01-19T20:14:13.965593Z","shell.execute_reply.started":"2025-01-19T20:14:13.961161Z","shell.execute_reply":"2025-01-19T20:14:13.964742Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"**Tokenize** ","metadata":{}},{"cell_type":"code","source":"# Initialize the BERT tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n\n# Function to tokenize data\ndef tokenize_data(texts, labels):\n    try:\n        if isinstance(texts, pd.Series):\n            texts = texts.tolist()\n        if isinstance(labels, pd.Series):\n            labels = labels.tolist()\n\n        encodings = tokenizer(\n            texts, \n            padding=True, \n            truncation=True, \n            max_length=367, \n            return_tensors=\"pt\"\n        )\n\n        dataset = CustomTextDataset(encodings, labels)\n        return dataset\n\n    except Exception as e:\n        print(f\"Error during tokenization: {e}\")\n        return None\n# Custom Dataset class\nclass CustomTextDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = [int(label) for label in labels]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:16.552120Z","iopub.execute_input":"2025-01-19T20:14:16.552402Z","iopub.status.idle":"2025-01-19T20:14:17.623293Z","shell.execute_reply.started":"2025-01-19T20:14:16.552378Z","shell.execute_reply":"2025-01-19T20:14:17.622687Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de1c3eee7ba0411bb095e615142b8fa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36151c714a884dad86e52b67e5428c37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd211058a4114fccaa8e026e743a6a68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67680e85917449f093d41c3256c1ad4a"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"train1_dataset = tokenize_data(train1_texts, train1_labels)\ntrain1_balanced_dataset = tokenize_data(df_balanced1_texts, df_balanced1_labels)\ntest_dataset = tokenize_data(test_texts, test_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:20.723168Z","iopub.execute_input":"2025-01-19T20:14:20.723479Z","iopub.status.idle":"2025-01-19T20:14:26.943897Z","shell.execute_reply.started":"2025-01-19T20:14:20.723454Z","shell.execute_reply":"2025-01-19T20:14:26.943217Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# # Prepare datasets\n# train_dataset = tokenize_data(train_texts, train_labels)\n# test_dataset = tokenize_data(test_texts, test_labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train1_loader = DataLoader(train1_dataset, batch_size=32, shuffle=True)\ntrain1_balanced_loader = DataLoader(train1_balanced_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:31.388902Z","iopub.execute_input":"2025-01-19T20:14:31.389214Z","iopub.status.idle":"2025-01-19T20:14:31.393282Z","shell.execute_reply.started":"2025-01-19T20:14:31.389187Z","shell.execute_reply":"2025-01-19T20:14:31.392534Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T21:49:44.999201Z","iopub.execute_input":"2025-01-15T21:49:44.999488Z","iopub.status.idle":"2025-01-15T21:49:45.003535Z","shell.execute_reply.started":"2025-01-15T21:49:44.999457Z","shell.execute_reply":"2025-01-15T21:49:45.002788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model1 = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 8)\nmodel1_balanced = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 8)\n\nmodel1.to(device)\nmodel1_balanced.to(device)# Move model to GPU if available\noptimizer1 = AdamW(model1.parameters(), lr=5e-5)\noptimizer1_balanced = AdamW(model1_balanced.parameters(), lr=5e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:59.821936Z","iopub.execute_input":"2025-01-19T20:14:59.822227Z","iopub.status.idle":"2025-01-19T20:15:01.919157Z","shell.execute_reply.started":"2025-01-19T20:14:59.822205Z","shell.execute_reply":"2025-01-19T20:15:01.918361Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5856a13f0e1b481cbf2f1fa4282194a8"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"print(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T18:46:00.447685Z","iopub.execute_input":"2025-01-19T18:46:00.448038Z","iopub.status.idle":"2025-01-19T18:46:00.452819Z","shell.execute_reply.started":"2025-01-19T18:46:00.448008Z","shell.execute_reply":"2025-01-19T18:46:00.451565Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"# Training loop\nmodel1.train()\n\nfor epoch in range(4):  # Train for 4 epochs\n    for batch in train1_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model1(**batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer1.step()\n        optimizer1.zero_grad()\n    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T18:46:48.075327Z","iopub.execute_input":"2025-01-19T18:46:48.075642Z","iopub.status.idle":"2025-01-19T18:49:16.724979Z","shell.execute_reply.started":"2025-01-19T18:46:48.075619Z","shell.execute_reply":"2025-01-19T18:49:16.724227Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 2.0737757682800293\nEpoch 2, Loss: 1.3507673740386963\nEpoch 3, Loss: 0.3720700740814209\nEpoch 4, Loss: 0.2362169325351715\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"# # Training loop\n# model1_balanced.train()\n\n# for epoch in range(4):  # Train for 4 epochs\n#     for batch in train1_balanced_loader:\n#         batch = {k: v.to(device) for k, v in batch.items()}\n#         outputs = model1_balanced(**batch)\n#         loss = outputs.loss\n#         loss.backward()\n#         optimizer1_balanced.step()\n#         optimizer1_balanced.zero_grad()\n#     print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T18:49:37.799489Z","iopub.execute_input":"2025-01-19T18:49:37.799805Z","iopub.status.idle":"2025-01-19T18:54:23.933935Z","shell.execute_reply.started":"2025-01-19T18:49:37.799780Z","shell.execute_reply":"2025-01-19T18:54:23.932950Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 1.054932713508606\nEpoch 2, Loss: 0.6145038604736328\nEpoch 3, Loss: 0.17743824422359467\nEpoch 4, Loss: 0.11474393308162689\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"model1_balanced.train()  # Set the model to training mode\n\nfor epoch in range(4):  # Train for 4 epochs\n    total_loss = 0\n    total_correct = 0\n    total_examples = 0\n\n    for batch in train1_balanced_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}  # Move batch to device\n        outputs = model1_balanced(**batch)  # Forward pass\n        loss = outputs.loss\n        loss.backward()  # Backpropagation\n        optimizer1_balanced.step()  # Update parameters\n        optimizer1_balanced.zero_grad()  # Clear gradients\n\n        # Calculate the loss\n        total_loss += loss.item()\n\n        # Calculate accuracy\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        total_correct += (predictions == batch['labels']).sum().item()\n        total_examples += predictions.size(0)\n\n    # Calculate average loss and accuracy for the epoch\n    avg_loss = total_loss / len(train1_balanced_loader)\n    avg_accuracy = 100 * total_correct / total_examples\n\n    print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.2f}, Accuracy: {avg_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:15:09.878253Z","iopub.execute_input":"2025-01-19T20:15:09.878552Z","iopub.status.idle":"2025-01-19T20:19:55.515870Z","shell.execute_reply.started":"2025-01-19T20:15:09.878528Z","shell.execute_reply":"2025-01-19T20:19:55.514723Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 1.55, Accuracy: 44.58%\nEpoch 2, Loss: 0.70, Accuracy: 78.16%\nEpoch 3, Loss: 0.27, Accuracy: 93.39%\nEpoch 4, Loss: 0.12, Accuracy: 97.14%\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"model1.eval()\ntotal1_eval_accuracy = 0\ntotal1_eval_loss = 0\n\nfor batch in test_loader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model1(**batch)\n\n    logits = outputs.logits\n    loss = outputs.loss\n    total1_eval_loss += loss.item()\n\n    predictions = torch.argmax(logits, dim=-1)\n    accuracy = (predictions == batch['labels']).cpu().numpy().mean() * 100\n    total1_eval_accuracy += accuracy\n\navg1_test_accuracy = total1_eval_accuracy / len(test_loader)\navg1_test_loss = total1_eval_loss / len(test_loader)\n\nprint(f\"For unballanced: Test Loss: {avg1_test_loss}, Test Accuracy: {avg1_test_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T18:55:03.903985Z","iopub.execute_input":"2025-01-19T18:55:03.904281Z","iopub.status.idle":"2025-01-19T18:55:15.907080Z","shell.execute_reply.started":"2025-01-19T18:55:03.904257Z","shell.execute_reply":"2025-01-19T18:55:15.906132Z"}},"outputs":[{"name":"stdout","text":"For unballanced: Test Loss: 1.2131333030187166, Test Accuracy: 61.51175213675214\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"model1_balanced.eval()\ntotal1_balanced_eval_accuracy = 0\ntotal1_balanced_eval_loss = 0\n\nfor batch in test_loader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model1_balanced(**batch)\n\n    logits = outputs.logits\n    loss = outputs.loss\n    total1_balanced_eval_loss += loss.item()\n\n    predictions = torch.argmax(logits, dim=-1)\n    accuracy = (predictions == batch['labels']).cpu().numpy().mean() * 100\n    total1_balanced_eval_accuracy += accuracy\n\navg1_balanced_test_accuracy = total1_balanced_eval_accuracy / len(test_loader)\navg1_balanced_test_loss = total1_balanced_eval_loss / len(test_loader)\n\nprint(f\"For ballanced: Test Loss: {avg1_balanced_test_loss}, Test Accuracy: {avg1_balanced_test_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:20:15.814546Z","iopub.execute_input":"2025-01-19T20:20:15.814870Z","iopub.status.idle":"2025-01-19T20:20:27.746686Z","shell.execute_reply.started":"2025-01-19T20:20:15.814846Z","shell.execute_reply":"2025-01-19T20:20:27.745957Z"}},"outputs":[{"name":"stdout","text":"For ballanced: Test Loss: 1.3438816529053907, Test Accuracy: 62.28632478632478\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Assuming you have the test_loader set up and the model in evaluation mode\npredictions1, true_labels1 = [], []\n\nfor batch in test_loader:\n    # Move batch to the appropriate device\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model1(**batch)\n\n    logits = outputs.logits\n    pred_labels = torch.argmax(logits, dim=-1)\n\n    # Collect predictions and true labels\n    predictions1.extend(pred_labels.cpu().numpy())\n    true_labels1.extend(batch['labels'].cpu().numpy())\n\nf1 = f1_score(true_labels1, predictions1, average='weighted')  # Change 'weighted' to 'macro' if needed\n\nprint(f\"For unbalanced: F1 Score: {f1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T18:55:51.255934Z","iopub.execute_input":"2025-01-19T18:55:51.256425Z","iopub.status.idle":"2025-01-19T18:56:03.580747Z","shell.execute_reply.started":"2025-01-19T18:55:51.256388Z","shell.execute_reply":"2025-01-19T18:56:03.579888Z"}},"outputs":[{"name":"stdout","text":"For unbalanced: F1 Score: 0.6235038470799567\n","output_type":"stream"}],"execution_count":100},{"cell_type":"code","source":"# Assuming you have the test_loader set up and the model in evaluation mode\npredictions1_balanced, true_labels1_balanced = [], []\n\nfor batch in test_loader:\n    # Move batch to the appropriate device\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model1_balanced(**batch)\n\n    logits = outputs.logits\n    pred_labels = torch.argmax(logits, dim=-1)\n\n    # Collect predictions and true labels\n    predictions1_balanced.extend(pred_labels.cpu().numpy())\n    true_labels1_balanced.extend(batch['labels'].cpu().numpy())\n\nf1 = f1_score(true_labels1_balanced, predictions1_balanced, average='weighted')  # Change 'weighted' to 'macro' if needed\n\nprint(f\"For balanced: F1 Score: {f1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:20:39.542186Z","iopub.execute_input":"2025-01-19T20:20:39.542478Z","iopub.status.idle":"2025-01-19T20:20:51.860806Z","shell.execute_reply.started":"2025-01-19T20:20:39.542455Z","shell.execute_reply":"2025-01-19T20:20:51.859978Z"}},"outputs":[{"name":"stdout","text":"For balanced: F1 Score: 0.6222021720416662\n","output_type":"stream"}],"execution_count":26}]}