{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:49:29.803996Z",
     "iopub.status.busy": "2025-01-15T21:49:29.803709Z",
     "iopub.status.idle": "2025-01-15T21:49:36.536518Z",
     "shell.execute_reply": "2025-01-15T21:49:36.535891Z",
     "shell.execute_reply.started": "2025-01-15T21:49:29.803967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add a column to turn the label column to numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:49:36.537549Z",
     "iopub.status.busy": "2025-01-15T21:49:36.537200Z",
     "iopub.status.idle": "2025-01-15T21:49:36.541256Z",
     "shell.execute_reply": "2025-01-15T21:49:36.540283Z",
     "shell.execute_reply.started": "2025-01-15T21:49:36.537527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:49:36.542280Z",
     "iopub.status.busy": "2025-01-15T21:49:36.542015Z",
     "iopub.status.idle": "2025-01-15T21:49:36.561788Z",
     "shell.execute_reply": "2025-01-15T21:49:36.560955Z",
     "shell.execute_reply.started": "2025-01-15T21:49:36.542255Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_number(label):\n",
    "    match = re.match(r'(\\d+)_', label)\n",
    "    if match:\n",
    "        return int(match.group(1))  \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- source of data: https://huggingface.co/datasets/QuotaClimat/frugalaichallenge-text-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:49:36.563957Z",
     "iopub.status.busy": "2025-01-15T21:49:36.563767Z",
     "iopub.status.idle": "2025-01-15T21:49:36.816868Z",
     "shell.execute_reply": "2025-01-15T21:49:36.816195Z",
     "shell.execute_reply.started": "2025-01-15T21:49:36.563941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../input/train-parquet')\n",
    "df['numeric_label'] = df['label'].apply(extract_number)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:49:36.818209Z",
     "iopub.status.busy": "2025-01-15T21:49:36.817962Z",
     "iopub.status.idle": "2025-01-15T21:49:36.830493Z",
     "shell.execute_reply": "2025-01-15T21:49:36.829796Z",
     "shell.execute_reply.started": "2025-01-15T21:49:36.818189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['quote'], df['numeric_label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:49:36.831718Z",
     "iopub.status.busy": "2025-01-15T21:49:36.831386Z",
     "iopub.status.idle": "2025-01-15T21:49:36.920034Z",
     "shell.execute_reply": "2025-01-15T21:49:36.918954Z",
     "shell.execute_reply.started": "2025-01-15T21:49:36.831687Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distilbert should be less energy consuming, it has less params \n",
    "- Lower case so less params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:49:36.921118Z",
     "iopub.status.busy": "2025-01-15T21:49:36.920866Z",
     "iopub.status.idle": "2025-01-15T21:49:44.998371Z",
     "shell.execute_reply": "2025-01-15T21:49:44.997540Z",
     "shell.execute_reply.started": "2025-01-15T21:49:36.921097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1df273330c34a4190ddf234e8c04008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b49a9915eec4485a1fdeb1e6fe7e1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb8183446d44a49b6b597c469986dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c2a499d7ab436099ce7f959a03c941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the BERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Function to tokenize data\n",
    "def tokenize_data(texts, labels):\n",
    "    encodings = tokenizer(texts.tolist(), padding=True, truncation=True, max_length=367, return_tensors=\"pt\")\n",
    "    dataset = CustomTextDataset(encodings, labels.tolist())\n",
    "    return dataset\n",
    "\n",
    "# Custom Dataset class\n",
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = [int(label) for label in labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = tokenize_data(train_texts, train_labels)\n",
    "test_dataset = tokenize_data(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:49:44.999488Z",
     "iopub.status.busy": "2025-01-15T21:49:44.999201Z",
     "iopub.status.idle": "2025-01-15T21:49:45.003535Z",
     "shell.execute_reply": "2025-01-15T21:49:45.002788Z",
     "shell.execute_reply.started": "2025-01-15T21:49:44.999457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:49:45.004718Z",
     "iopub.status.busy": "2025-01-15T21:49:45.004445Z",
     "iopub.status.idle": "2025-01-15T21:49:47.446348Z",
     "shell.execute_reply": "2025-01-15T21:49:47.445630Z",
     "shell.execute_reply.started": "2025-01-15T21:49:45.004699Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb512bcb7583446fb0482cc65ea9a972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 8)\n",
    "model.to(device)  # Move model to GPU if available\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:49:47.447592Z",
     "iopub.status.busy": "2025-01-15T21:49:47.447105Z",
     "iopub.status.idle": "2025-01-15T21:49:47.451997Z",
     "shell.execute_reply": "2025-01-15T21:49:47.450965Z",
     "shell.execute_reply.started": "2025-01-15T21:49:47.447567Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:49:47.453162Z",
     "iopub.status.busy": "2025-01-15T21:49:47.452871Z",
     "iopub.status.idle": "2025-01-15T21:59:31.647387Z",
     "shell.execute_reply": "2025-01-15T21:59:31.646684Z",
     "shell.execute_reply.started": "2025-01-15T21:49:47.453131Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8415148258209229\n",
      "Epoch 2, Loss: 0.5734939575195312\n",
      "Epoch 3, Loss: 0.7246766090393066\n",
      "Epoch 4, Loss: 0.09047771990299225\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "\n",
    "for epoch in range(4):  # Train for 4 epochs\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:59:31.648541Z",
     "iopub.status.busy": "2025-01-15T21:59:31.648232Z",
     "iopub.status.idle": "2025-01-15T21:59:45.141322Z",
     "shell.execute_reply": "2025-01-15T21:59:45.140587Z",
     "shell.execute_reply.started": "2025-01-15T21:59:31.648511Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1808117994895349, Test Accuracy: 66.07905982905983\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_eval_accuracy = 0\n",
    "total_eval_loss = 0\n",
    "\n",
    "for batch in test_loader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    loss = outputs.loss\n",
    "    total_eval_loss += loss.item()\n",
    "\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    accuracy = (predictions == batch['labels']).cpu().numpy().mean() * 100\n",
    "    total_eval_accuracy += accuracy\n",
    "\n",
    "avg_test_accuracy = total_eval_accuracy / len(test_loader)\n",
    "avg_test_loss = total_eval_loss / len(test_loader)\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss}, Test Accuracy: {avg_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T21:59:45.143554Z",
     "iopub.status.busy": "2025-01-15T21:59:45.143344Z",
     "iopub.status.idle": "2025-01-15T21:59:58.599157Z",
     "shell.execute_reply": "2025-01-15T21:59:58.598430Z",
     "shell.execute_reply.started": "2025-01-15T21:59:45.143536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Assuming you have the test_loader set up and the model in evaluation mode\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "for batch in test_loader:\n",
    "    # Move batch to the appropriate device\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    pred_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Collect predictions and true labels\n",
    "    predictions.extend(pred_labels.cpu().numpy())\n",
    "    true_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "# Now predictions and true_labels are complete lists of all test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:00:22.479136Z",
     "iopub.status.busy": "2025-01-15T22:00:22.478827Z",
     "iopub.status.idle": "2025-01-15T22:00:22.496432Z",
     "shell.execute_reply": "2025-01-15T22:00:22.495481Z",
     "shell.execute_reply.started": "2025-01-15T22:00:22.479110Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6681854882211213\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(true_labels, predictions, average='weighted')  # Change 'weighted' to 'macro' if needed\n",
    "\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:00:24.812106Z",
     "iopub.status.busy": "2025-01-15T22:00:24.811793Z",
     "iopub.status.idle": "2025-01-15T22:00:25.144117Z",
     "shell.execute_reply": "2025-01-15T22:00:25.143331Z",
     "shell.execute_reply.started": "2025-01-15T22:00:24.812081Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model1 = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 8)\n",
    "for name, param in model1.named_parameters():\n",
    "    if 'classifier' not in name:  # Freeze layers that are not part of the classifier\n",
    "        param.requires_grad = False\n",
    "\n",
    "model1.to(device)  # Move model to GPU if available\n",
    "optimizer = AdamW(model1.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:02:57.788665Z",
     "iopub.status.busy": "2025-01-15T22:02:57.788218Z",
     "iopub.status.idle": "2025-01-15T22:06:40.031105Z",
     "shell.execute_reply": "2025-01-15T22:06:40.030304Z",
     "shell.execute_reply.started": "2025-01-15T22:02:57.788625Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch for model1 1, Loss for model1: 1.5037622451782227\n",
      "Epoch for model1 2, Loss for model1: 1.338724136352539\n",
      "Epoch for model1 3, Loss for model1: 1.685149073600769\n",
      "Epoch for model1 4, Loss for model1: 1.957392692565918\n"
     ]
    }
   ],
   "source": [
    "model1.train()\n",
    "\n",
    "for epoch in range(4):  # Train for 4 epochs\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model1(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f\"Epoch for model1 {epoch + 1}, Loss for model1: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:08:35.369261Z",
     "iopub.status.busy": "2025-01-15T22:08:35.368936Z",
     "iopub.status.idle": "2025-01-15T22:08:47.949223Z",
     "shell.execute_reply": "2025-01-15T22:08:47.948348Z",
     "shell.execute_reply.started": "2025-01-15T22:08:35.369234Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss for model1: 1.3746979847932472, Test Accuracy for model1: 49.83974358974359\n"
     ]
    }
   ],
   "source": [
    "model1.eval()\n",
    "total_eval_accuracy = 0\n",
    "total_eval_loss = 0\n",
    "\n",
    "for batch in test_loader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model1(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    loss = outputs.loss\n",
    "    total_eval_loss += loss.item()\n",
    "\n",
    "    predictions1 = torch.argmax(logits, dim=-1)\n",
    "    accuracy = (predictions1 == batch['labels']).cpu().numpy().mean() * 100\n",
    "    total_eval_accuracy += accuracy\n",
    "\n",
    "avg_test_accuracy = total_eval_accuracy / len(test_loader)\n",
    "avg_test_loss = total_eval_loss / len(test_loader)\n",
    "\n",
    "print(f\"Test Loss for model1: {avg_test_loss}, Test Accuracy for model1: {avg_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:08:51.267229Z",
     "iopub.status.busy": "2025-01-15T22:08:51.266798Z",
     "iopub.status.idle": "2025-01-15T22:09:03.991656Z",
     "shell.execute_reply": "2025-01-15T22:09:03.990964Z",
     "shell.execute_reply.started": "2025-01-15T22:08:51.267190Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Assuming you have the test_loader set up and the model in evaluation mode\n",
    "predictions1, true_labels = [], []\n",
    "\n",
    "for batch in test_loader:\n",
    "    # Move batch to the appropriate device\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    pred_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Collect predictions and true labels\n",
    "    predictions1.extend(pred_labels.cpu().numpy())\n",
    "    true_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "# Now predictions and true_labels are complete lists of all test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:09:12.475093Z",
     "iopub.status.busy": "2025-01-15T22:09:12.474791Z",
     "iopub.status.idle": "2025-01-15T22:09:12.482828Z",
     "shell.execute_reply": "2025-01-15T22:09:12.482100Z",
     "shell.execute_reply.started": "2025-01-15T22:09:12.475070Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for model1: 0.6681854882211213\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(true_labels, predictions1, average='weighted')  # Change 'weighted' to 'macro' if needed\n",
    "\n",
    "print(f\"F1 Score for model1: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6483657,
     "sourceId": 10471355,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
