{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10471355,"sourceType":"datasetVersion","datasetId":6483657},{"sourceId":10542548,"sourceType":"datasetVersion","datasetId":6523213},{"sourceId":218658144,"sourceType":"kernelVersion"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install nlpaug","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:24:42.134375Z","iopub.execute_input":"2025-01-21T20:24:42.134836Z","iopub.status.idle":"2025-01-21T20:24:46.688726Z","shell.execute_reply.started":"2025-01-21T20:24:42.134798Z","shell.execute_reply":"2025-01-21T20:24:46.687828Z"}},"outputs":[{"name":"stdout","text":"Collecting nlpaug\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.26.4)\nRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.2.2)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.32.3)\nRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.16.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.12.14)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.6)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.2->nlpaug) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nlpaug\nSuccessfully installed nlpaug-1.1.11\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport re\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\nimport nlpaug.augmenter.word as naw\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:24:50.129218Z","iopub.execute_input":"2025-01-21T20:24:50.129534Z","iopub.status.idle":"2025-01-21T20:25:14.828503Z","shell.execute_reply.started":"2025-01-21T20:24:50.129511Z","shell.execute_reply":"2025-01-21T20:25:14.827760Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"- source of data: https://huggingface.co/datasets/QuotaClimat/frugalaichallenge-text-train","metadata":{}},{"cell_type":"code","source":"train1 = pd.read_csv('/kaggle/input/d/rafechang/balanced/train1.csv')\ntrain2 = pd.read_csv('/kaggle/input/d/rafechang/balanced/train2.csv')\ntrain3 = pd.read_csv('/kaggle/input/d/rafechang/balanced/train3.csv')\ntrain4 = pd.read_csv('/kaggle/input/d/rafechang/balanced/train4.csv')\ntest = pd.read_csv('/kaggle/input/d/rafechang/balanced/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:27:08.140287Z","iopub.execute_input":"2025-01-21T20:27:08.141054Z","iopub.status.idle":"2025-01-21T20:27:08.326073Z","shell.execute_reply.started":"2025-01-21T20:27:08.141025Z","shell.execute_reply":"2025-01-21T20:27:08.325418Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:27:18.831752Z","iopub.execute_input":"2025-01-21T20:27:18.832051Z","iopub.status.idle":"2025-01-21T20:27:18.911598Z","shell.execute_reply.started":"2025-01-21T20:27:18.832030Z","shell.execute_reply":"2025-01-21T20:27:18.910700Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"- Distilbert should be less energy consuming, it has less params \n- Lower case so less params ","metadata":{}},{"cell_type":"markdown","source":"**split data**","metadata":{}},{"cell_type":"code","source":"train1_texts = train1['quote']\ntrain1_labels = train1['numeric_label']\ntrain2_texts = train2['quote']\ntrain2_labels = train2['numeric_label']\ntrain3_texts = train3['quote']\ntrain3_labels = train3['numeric_label']\ntrain4_texts = train4['quote']\ntrain4_labels = train4['numeric_label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:27:22.323873Z","iopub.execute_input":"2025-01-21T20:27:22.324185Z","iopub.status.idle":"2025-01-21T20:27:22.333144Z","shell.execute_reply.started":"2025-01-21T20:27:22.324158Z","shell.execute_reply":"2025-01-21T20:27:22.332431Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"test_texts = test['quote']\ntest_labels = test['numeric_label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:27:24.500789Z","iopub.execute_input":"2025-01-21T20:27:24.501061Z","iopub.status.idle":"2025-01-21T20:27:24.505048Z","shell.execute_reply.started":"2025-01-21T20:27:24.501042Z","shell.execute_reply":"2025-01-21T20:27:24.504080Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"**Tokenize** ","metadata":{}},{"cell_type":"code","source":"# Initialize the BERT tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n\n# Function to tokenize data\ndef tokenize_data(texts, labels):\n    try:\n        if isinstance(texts, pd.Series):\n            texts = texts.tolist()\n        if isinstance(labels, pd.Series):\n            labels = labels.tolist()\n\n        encodings = tokenizer(\n            texts, \n            padding=True, \n            truncation=True, \n            max_length=367, \n            return_tensors=\"pt\"\n        )\n\n        dataset = CustomTextDataset(encodings, labels)\n        return dataset\n\n    except Exception as e:\n        print(f\"Error during tokenization: {e}\")\n        return None\n# Custom Dataset class\nclass CustomTextDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = [int(label) for label in labels]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:27:27.265403Z","iopub.execute_input":"2025-01-21T20:27:27.265793Z","iopub.status.idle":"2025-01-21T20:27:28.389176Z","shell.execute_reply.started":"2025-01-21T20:27:27.265762Z","shell.execute_reply":"2025-01-21T20:27:28.388503Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6342d3a2df149d7bace54b3b1b11704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"537ae5453bab4710a6e34353751a05ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f253ded05ef4b86b7a2320e6fffbffb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe9eed09727a4ff38465635115ccc44b"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"train1_dataset = tokenize_data(train1_texts, train1_labels)\ntrain2_dataset = tokenize_data(train2_texts, train2_labels)\ntrain3_dataset = tokenize_data(train3_texts, train3_labels)\ntrain4_dataset = tokenize_data(train4_texts, train4_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:27:43.482799Z","iopub.execute_input":"2025-01-21T20:27:43.483079Z","iopub.status.idle":"2025-01-21T20:27:57.755271Z","shell.execute_reply.started":"2025-01-21T20:27:43.483058Z","shell.execute_reply":"2025-01-21T20:27:57.754148Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"test_dataset = tokenize_data(test_texts, test_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:27:59.777208Z","iopub.execute_input":"2025-01-21T20:27:59.777558Z","iopub.status.idle":"2025-01-21T20:28:01.305631Z","shell.execute_reply.started":"2025-01-21T20:27:59.777532Z","shell.execute_reply":"2025-01-21T20:28:01.304766Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train1_loader = DataLoader(train1_dataset, batch_size=32, shuffle=True)\ntrain2_loader = DataLoader(train2_dataset, batch_size=32, shuffle=True)\ntrain3_loader = DataLoader(train3_dataset, batch_size=32, shuffle=True)\ntrain4_loader = DataLoader(train4_dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:28:03.602386Z","iopub.execute_input":"2025-01-21T20:28:03.602731Z","iopub.status.idle":"2025-01-21T20:28:03.607268Z","shell.execute_reply.started":"2025-01-21T20:28:03.602693Z","shell.execute_reply":"2025-01-21T20:28:03.606246Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:28:06.851945Z","iopub.execute_input":"2025-01-21T20:28:06.852296Z","iopub.status.idle":"2025-01-21T20:28:06.855902Z","shell.execute_reply.started":"2025-01-21T20:28:06.852271Z","shell.execute_reply":"2025-01-21T20:28:06.855134Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model1 = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 8)\nmodel1.to(device)\noptimizer1 = AdamW(model1.parameters(), lr=5e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:28:09.656085Z","iopub.execute_input":"2025-01-21T20:28:09.656425Z","iopub.status.idle":"2025-01-21T20:28:11.715637Z","shell.execute_reply.started":"2025-01-21T20:28:09.656396Z","shell.execute_reply":"2025-01-21T20:28:11.714835Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29f1e4ff71e74038b2c1e6e14edcf717"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:28:14.664624Z","iopub.execute_input":"2025-01-21T20:28:14.665194Z","iopub.status.idle":"2025-01-21T20:28:14.670432Z","shell.execute_reply.started":"2025-01-21T20:28:14.665141Z","shell.execute_reply":"2025-01-21T20:28:14.669337Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Step 1: train on train1 and validate on train 2 ","metadata":{}},{"cell_type":"code","source":"model1.train()  # Set the model to training mode\n\nfor epoch in range(2):  # Train for 4 epochs\n    total_loss = 0\n    total_correct = 0\n    total_examples = 0\n\n    for batch in train1_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}  # Move batch to device\n        outputs = model1(**batch)  # Forward pass\n        loss = outputs.loss\n        loss.backward()  # Backpropagation\n        optimizer1.step()  # Update parameters\n        optimizer1.zero_grad()  # Clear gradients\n\n        # Calculate the loss\n        total_loss += loss.item()\n\n        # Calculate accuracy\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        total_correct += (predictions == batch['labels']).sum().item()\n        total_examples += predictions.size(0)\n\n    # Calculate average loss and accuracy for the epoch\n    avg_loss = total_loss / len(train1_loader)\n    avg_accuracy = 100 * total_correct / total_examples\n\n    print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.2f}, Accuracy: {avg_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:28:17.145277Z","iopub.execute_input":"2025-01-21T20:28:17.145574Z","iopub.status.idle":"2025-01-21T20:30:40.323581Z","shell.execute_reply.started":"2025-01-21T20:28:17.145552Z","shell.execute_reply":"2025-01-21T20:30:40.322689Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 1.50, Accuracy: 48.59%\nEpoch 2, Loss: 0.71, Accuracy: 78.41%\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model1.eval()\ntotal1_eval_accuracy = 0\ntotal1_eval_loss = 0\n\nfor batch in train2_loader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model1(**batch)\n\n    logits = outputs.logits\n    loss = outputs.loss\n    total1_eval_loss += loss.item()\n\n    predictions = torch.argmax(logits, dim=-1)\n    accuracy = (predictions == batch['labels']).cpu().numpy().mean() * 100\n    total1_eval_accuracy += accuracy\n\navg1_test_accuracy = total1_eval_accuracy / len(train2_loader)\navg1_test_loss = total1_eval_loss / len(train2_loader)\n\nprint(f\"Test Loss: {avg1_test_loss}, Test Accuracy: {avg1_test_accuracy}\")\n\npredictions1, true_labels1 = [], []\n\nfor batch in train2_loader:\n    # Move batch to the appropriate device\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model1(**batch)\n\n    logits = outputs.logits\n    pred_labels = torch.argmax(logits, dim=-1)\n\n    # Collect predictions and true labels\n    predictions1.extend(pred_labels.cpu().numpy())\n    true_labels1.extend(batch['labels'].cpu().numpy())\n\nf1 = f1_score(true_labels1, predictions1, average='weighted')  # Change 'weighted' to 'macro' if needed\n\nprint(f\"F1 Score: {f1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:30:53.025197Z","iopub.execute_input":"2025-01-21T20:30:53.025519Z","iopub.status.idle":"2025-01-21T20:31:54.332809Z","shell.execute_reply.started":"2025-01-21T20:30:53.025496Z","shell.execute_reply":"2025-01-21T20:31:54.331833Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 1.305559082921729, Test Accuracy: 55.38403614457831\nF1 Score: 0.5474014188718019\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Step 2: train on train1+train 2, validate on train 3","metadata":{}},{"cell_type":"code","source":"train12_texts = pd.concat([train1_texts, train2_texts], ignore_index=True)\ntrain12_labels = pd.concat([train1_labels, train2_labels], ignore_index=True)\ntrain12_dataset = tokenize_data(train12_texts, train12_labels)\ntrain12_loader = DataLoader(train12_dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:31:54.334091Z","iopub.execute_input":"2025-01-21T20:31:54.334491Z","iopub.status.idle":"2025-01-21T20:32:01.013745Z","shell.execute_reply.started":"2025-01-21T20:31:54.334451Z","shell.execute_reply":"2025-01-21T20:32:01.012946Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model1.train()  # Set the model to training mode\n\nfor epoch in range(2):  # Train for 4 epochs\n    total_loss = 0\n    total_correct = 0\n    total_examples = 0\n\n    for batch in train12_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}  # Move batch to device\n        outputs = model1(**batch)  # Forward pass\n        loss = outputs.loss\n        loss.backward()  # Backpropagation\n        optimizer1.step()  # Update parameters\n        optimizer1.zero_grad()  # Clear gradients\n\n        # Calculate the loss\n        total_loss += loss.item()\n\n        # Calculate accuracy\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        total_correct += (predictions == batch['labels']).sum().item()\n        total_examples += predictions.size(0)\n\n    # Calculate average loss and accuracy for the epoch\n    avg_loss = total_loss / len(train12_loader)\n    avg_accuracy = 100 * total_correct / total_examples\n\n    print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.2f}, Accuracy: {avg_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:32:13.984641Z","iopub.execute_input":"2025-01-21T20:32:13.984956Z","iopub.status.idle":"2025-01-21T20:37:47.300977Z","shell.execute_reply.started":"2025-01-21T20:32:13.984937Z","shell.execute_reply":"2025-01-21T20:37:47.300131Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.65, Accuracy: 79.39%\nEpoch 2, Loss: 0.23, Accuracy: 93.88%\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"model1.eval()\ntotal2_eval_accuracy = 0\ntotal2_eval_loss = 0\n\nfor batch in train3_loader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model1(**batch)\n\n    logits = outputs.logits\n    loss = outputs.loss\n    total2_eval_loss += loss.item()\n\n    predictions = torch.argmax(logits, dim=-1)\n    accuracy = (predictions == batch['labels']).cpu().numpy().mean() * 100\n    total2_eval_accuracy += accuracy\n\navg2_test_accuracy = total2_eval_accuracy / len(train3_loader)\navg2_test_loss = total2_eval_loss / len(train3_loader)\n\nprint(f\"Test Loss: {avg2_test_loss}, Test Accuracy: {avg2_test_accuracy}\")\n\npredictions2, true_labels2 = [], []\n\nfor batch in train3_loader:\n    # Move batch to the appropriate device\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model1(**batch)\n\n    logits = outputs.logits\n    pred_labels = torch.argmax(logits, dim=-1)\n\n    # Collect predictions and true labels\n    predictions2.extend(pred_labels.cpu().numpy())\n    true_labels2.extend(batch['labels'].cpu().numpy())\n\nf12 = f1_score(true_labels2, predictions2, average='weighted')  # Change 'weighted' to 'macro' if needed\n\nprint(f\"F1 Score: {f12}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:37:53.344997Z","iopub.execute_input":"2025-01-21T20:37:53.345332Z","iopub.status.idle":"2025-01-21T20:38:54.147262Z","shell.execute_reply.started":"2025-01-21T20:37:53.345308Z","shell.execute_reply":"2025-01-21T20:38:54.146386Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 1.3301386165331646, Test Accuracy: 62.838855421686745\nF1 Score: 0.6300865572426506\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"Step 3: train on train1+train2+train3, validate on train4 ","metadata":{}},{"cell_type":"code","source":"train123_texts = pd.concat([train12_texts, train3_texts], ignore_index=True)\ntrain123_labels = pd.concat([train12_labels, train3_labels], ignore_index=True)\ntrain123_dataset = tokenize_data(train123_texts, train123_labels)\ntrain123_loader = DataLoader(train123_dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:38:54.148526Z","iopub.execute_input":"2025-01-21T20:38:54.148896Z","iopub.status.idle":"2025-01-21T20:39:04.442770Z","shell.execute_reply.started":"2025-01-21T20:38:54.148860Z","shell.execute_reply":"2025-01-21T20:39:04.442097Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"model1.train()  # Set the model to training mode\n\nfor epoch in range(2):  # Train for 4 epochs\n    total_loss = 0\n    total_correct = 0\n    total_examples = 0\n\n    for batch in train123_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}  # Move batch to device\n        outputs = model1(**batch)  # Forward pass\n        loss = outputs.loss\n        loss.backward()  # Backpropagation\n        optimizer1.step()  # Update parameters\n        optimizer1.zero_grad()  # Clear gradients\n\n        # Calculate the loss\n        total_loss += loss.item()\n\n        # Calculate accuracy\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        total_correct += (predictions == batch['labels']).sum().item()\n        total_examples += predictions.size(0)\n\n    # Calculate average loss and accuracy for the epoch\n    avg_loss = total_loss / len(train123_loader)\n    avg_accuracy = 100 * total_correct / total_examples\n\n    print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.2f}, Accuracy: {avg_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:39:20.793723Z","iopub.execute_input":"2025-01-21T20:39:20.794036Z","iopub.status.idle":"2025-01-21T20:47:49.334990Z","shell.execute_reply.started":"2025-01-21T20:39:20.794011Z","shell.execute_reply":"2025-01-21T20:47:49.333959Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.39, Accuracy: 88.35%\nEpoch 2, Loss: 0.12, Accuracy: 96.55%\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"model1.eval()\ntotal3_eval_accuracy = 0\ntotal3_eval_loss = 0\n\nfor batch in train3_loader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model1(**batch)\n\n    logits = outputs.logits\n    loss = outputs.loss\n    total3_eval_loss += loss.item()\n\n    predictions = torch.argmax(logits, dim=-1)\n    accuracy = (predictions == batch['labels']).cpu().numpy().mean() * 100\n    total3_eval_accuracy += accuracy\n\navg3_test_accuracy = total3_eval_accuracy / len(train4_loader)\navg3_test_loss = total3_eval_loss / len(train4_loader)\n\nprint(f\"Test Loss: {avg3_test_loss}, Test Accuracy: {avg3_test_accuracy}\")\n\npredictions3, true_labels3 = [], []\n\nfor batch in train4_loader:\n    # Move batch to the appropriate device\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model1(**batch)\n\n    logits = outputs.logits\n    pred_labels = torch.argmax(logits, dim=-1)\n\n    # Collect predictions and true labels\n    predictions3.extend(pred_labels.cpu().numpy())\n    true_labels3.extend(batch['labels'].cpu().numpy())\n\nf123 = f1_score(true_labels3, predictions3, average='weighted')  # Change 'weighted' to 'macro' if needed\n\nprint(f\"F1 Score: {f123}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T20:47:54.550636Z","iopub.execute_input":"2025-01-21T20:47:54.550937Z","iopub.status.idle":"2025-01-21T20:48:58.060102Z","shell.execute_reply.started":"2025-01-21T20:47:54.550917Z","shell.execute_reply":"2025-01-21T20:48:58.059339Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.05661274696596795, Test Accuracy: 91.00694444444444\nF1 Score: 0.6020204597809806\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"Step 4: hyperparam optimization (only here since can be resource intensive) ","metadata":{}},{"cell_type":"code","source":"model1.","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}