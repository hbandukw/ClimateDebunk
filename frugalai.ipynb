{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10472257,"sourceType":"datasetVersion","datasetId":6484225}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Adam and AdamW are subtly different in terms of how they handle weight decay. AdamW modifies the weight decay process to decouple it from the gradient updates, which can lead to better training performance for some models like BERT. Hence, it's generally recommended to use AdamW for transformers.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.optim import AdamW\nfrom torch.utils.data import Dataset, DataLoader\nimport plotly.express as px\nfrom sklearn.metrics import f1_score\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T22:19:23.888782Z","iopub.execute_input":"2025-01-17T22:19:23.889181Z","iopub.status.idle":"2025-01-17T22:19:23.893487Z","shell.execute_reply.started":"2025-01-17T22:19:23.889152Z","shell.execute_reply":"2025-01-17T22:19:23.892621Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"**Data**","metadata":{}},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/climatetext/train.parquet\")\ndf['label_int'] = df['label'].str.split(\"_\").str[0]\ndf['label_int'] = df['label_int'].astype('int')    # get int label\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T22:19:26.194521Z","iopub.execute_input":"2025-01-17T22:19:26.194836Z","iopub.status.idle":"2025-01-17T22:19:26.390826Z","shell.execute_reply.started":"2025-01-17T22:19:26.194814Z","shell.execute_reply":"2025-01-17T22:19:26.389934Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                               quote  \\\n0  There is clear, compelling evidence that many ...   \n1  For most of the Holocene (last 10k years), sea...   \n2  China, which hosts U.N. climate talks next wee...   \n3  And the fabricated documents (which Dr. Mann a...   \n4  It's going to be 42 here today and the hottest...   \n\n                             label source  \\\n0             5_science_unreliable  FLICC   \n1                  1_not_happening  FLICC   \n2  4_solutions_harmful_unnecessary  FLICC   \n3                   0_not_relevant  FLICC   \n4                  1_not_happening  FLICC   \n\n                                                 url language      subsource  \\\n0  https://huggingface.co/datasets/fzanartu/FLICC...       en          CARDS   \n1  https://huggingface.co/datasets/fzanartu/FLICC...       en  hamburg_test1   \n2  https://huggingface.co/datasets/fzanartu/FLICC...       en          CARDS   \n3  https://huggingface.co/datasets/fzanartu/FLICC...       en          CARDS   \n4  https://huggingface.co/datasets/fzanartu/FLICC...       en  hamburg_test3   \n\n     id  label_int  \n0  None          5  \n1  None          1  \n2  None          4  \n3  None          0  \n4  None          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>quote</th>\n      <th>label</th>\n      <th>source</th>\n      <th>url</th>\n      <th>language</th>\n      <th>subsource</th>\n      <th>id</th>\n      <th>label_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>There is clear, compelling evidence that many ...</td>\n      <td>5_science_unreliable</td>\n      <td>FLICC</td>\n      <td>https://huggingface.co/datasets/fzanartu/FLICC...</td>\n      <td>en</td>\n      <td>CARDS</td>\n      <td>None</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>For most of the Holocene (last 10k years), sea...</td>\n      <td>1_not_happening</td>\n      <td>FLICC</td>\n      <td>https://huggingface.co/datasets/fzanartu/FLICC...</td>\n      <td>en</td>\n      <td>hamburg_test1</td>\n      <td>None</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>China, which hosts U.N. climate talks next wee...</td>\n      <td>4_solutions_harmful_unnecessary</td>\n      <td>FLICC</td>\n      <td>https://huggingface.co/datasets/fzanartu/FLICC...</td>\n      <td>en</td>\n      <td>CARDS</td>\n      <td>None</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>And the fabricated documents (which Dr. Mann a...</td>\n      <td>0_not_relevant</td>\n      <td>FLICC</td>\n      <td>https://huggingface.co/datasets/fzanartu/FLICC...</td>\n      <td>en</td>\n      <td>CARDS</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>It's going to be 42 here today and the hottest...</td>\n      <td>1_not_happening</td>\n      <td>FLICC</td>\n      <td>https://huggingface.co/datasets/fzanartu/FLICC...</td>\n      <td>en</td>\n      <td>hamburg_test3</td>\n      <td>None</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"label_counts = df['label'].value_counts().reset_index()\nlabel_counts.columns = ['label', 'count']\n\nfig = px.bar(label_counts, x='label', y='count', title='Distribution of Labels in the Data')\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T22:19:41.237555Z","iopub.execute_input":"2025-01-17T22:19:41.237907Z","iopub.status.idle":"2025-01-17T22:19:42.706181Z","shell.execute_reply.started":"2025-01-17T22:19:41.237853Z","shell.execute_reply":"2025-01-17T22:19:42.705204Z"}},"outputs":[{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"922265b4-26fb-4721-8784-8c72f95dcfce\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"922265b4-26fb-4721-8784-8c72f95dcfce\")) {                    Plotly.newPlot(                        \"922265b4-26fb-4721-8784-8c72f95dcfce\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"label=%{x}\\u003cbr\\u003ecount=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"0_not_relevant\",\"5_science_unreliable\",\"6_proponents_biased\",\"4_solutions_harmful_unnecessary\",\"1_not_happening\",\"2_not_human\",\"3_not_bad\",\"7_fossil_fuels_needed\"],\"xaxis\":\"x\",\"y\":[1618,801,782,774,741,702,386,287],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"label\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Distribution of Labels in the Data\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('922265b4-26fb-4721-8784-8c72f95dcfce');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"**Model** ","metadata":{}},{"cell_type":"markdown","source":"***Tokenizer***\n\n*Choosing Max lenght*\n\n75% percentile","metadata":{}},{"cell_type":"code","source":"df['quote_length'] = df['quote'].apply(len)\n\n# Using Plotly to create a histogram of quote lengths\nfig = px.histogram(df, x='quote_length', title='Distribution of Quote Lengths', \n                   labels={'quote_length': 'Length of Quote'}, \n                   nbins=30, color_discrete_sequence=['#636EFA'])  \nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T22:19:53.825006Z","iopub.execute_input":"2025-01-17T22:19:53.825320Z","iopub.status.idle":"2025-01-17T22:19:53.898837Z","shell.execute_reply.started":"2025-01-17T22:19:53.825297Z","shell.execute_reply":"2025-01-17T22:19:53.897820Z"}},"outputs":[{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b2e75492-b41a-4dac-9c9c-b6a86121384a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b2e75492-b41a-4dac-9c9c-b6a86121384a\")) {                    Plotly.newPlot(                        \"b2e75492-b41a-4dac-9c9c-b6a86121384a\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"Length of Quote=%{x}\\u003cbr\\u003ecount=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636EFA\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"nbinsx\":30,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[277,279,286,146,123,406,134,107,276,101,141,152,157,281,194,223,97,107,193,144,330,326,43,85,257,121,144,208,150,111,103,313,62,132,326,257,227,390,206,267,137,90,148,46,240,55,45,325,206,229,201,92,84,120,230,133,195,279,134,154,233,307,100,238,275,362,92,191,244,221,396,147,628,134,82,96,436,145,166,305,251,176,249,30,92,126,175,186,449,71,280,465,209,459,75,222,91,266,325,194,255,391,31,238,61,112,53,62,66,105,392,207,147,299,421,223,199,338,190,144,78,441,79,276,130,104,140,265,205,75,284,397,193,95,85,449,216,452,105,60,136,49,99,327,106,208,55,233,35,72,225,128,526,161,279,205,175,429,181,96,106,119,123,250,182,180,276,222,339,206,104,82,202,153,201,205,84,34,67,126,134,244,96,208,182,144,150,303,131,84,124,108,86,386,278,102,257,64,231,190,48,446,205,224,86,242,278,46,192,135,199,168,338,88,309,141,251,67,374,251,216,286,140,292,117,125,485,52,84,100,126,219,78,64,208,63,116,111,346,101,121,220,287,93,257,92,185,30,69,179,419,298,86,182,125,183,113,169,162,60,280,77,238,283,277,48,70,189,62,177,186,32,77,71,316,427,280,19,187,45,158,67,79,180,140,106,24,112,287,171,104,302,141,199,72,62,402,45,222,181,63,222,203,203,381,50,214,116,514,182,39,448,623,146,117,166,115,118,149,226,464,216,393,123,560,70,124,238,161,67,84,284,160,208,153,118,97,316,209,148,80,199,229,141,176,172,348,58,202,223,109,106,110,345,39,181,193,93,265,169,49,174,203,163,86,160,88,73,315,117,166,171,262,136,105,196,261,630,116,331,99,201,117,255,119,507,42,246,136,210,94,100,282,489,40,241,421,169,94,32,183,136,687,83,99,44,50,120,52,153,217,106,98,101,183,113,139,369,149,158,164,84,140,114,438,414,237,47,154,161,380,180,117,147,100,36,243,233,172,86,171,278,382,91,53,83,121,96,127,365,29,116,67,237,102,116,64,281,184,133,60,213,425,183,218,348,39,183,505,155,94,149,125,180,262,133,159,183,250,275,419,45,296,127,112,81,231,77,158,124,182,461,136,423,341,140,225,85,192,224,399,414,209,105,82,448,66,223,210,89,101,59,127,228,207,281,271,420,106,291,71,509,190,185,388,101,129,179,187,150,127,233,286,235,218,37,292,175,461,187,116,27,145,168,204,162,262,72,460,258,137,55,235,76,135,113,62,200,131,109,109,135,321,982,109,216,248,619,90,39,181,138,121,209,379,50,272,37,117,338,70,116,372,217,34,203,147,194,158,138,173,152,117,432,223,73,124,351,135,70,181,85,84,225,114,110,274,191,64,94,142,197,120,248,180,63,43,267,191,219,195,546,116,136,64,162,82,59,163,310,63,709,323,342,183,171,63,200,98,92,147,95,345,185,100,118,195,297,362,230,567,130,389,103,94,257,74,118,371,72,109,95,83,283,123,194,112,96,198,168,254,125,164,191,248,186,220,402,123,280,119,463,371,115,112,148,52,232,354,521,75,56,279,118,205,563,149,145,467,234,122,79,70,74,189,137,57,113,633,152,54,154,171,118,222,57,75,221,61,435,104,91,135,70,55,184,83,339,119,213,77,293,217,261,157,172,72,105,50,264,195,48,186,316,346,100,140,116,243,220,493,288,180,223,76,68,186,104,130,279,138,124,261,182,241,264,101,287,226,179,386,78,98,411,276,211,612,120,164,48,57,111,183,397,99,120,247,174,196,222,154,274,135,153,220,115,159,93,258,167,46,160,79,82,211,51,174,58,245,157,135,39,263,181,121,213,157,211,230,233,164,398,295,171,65,32,158,60,214,164,252,241,593,51,96,142,150,199,154,167,234,42,107,110,154,168,281,129,299,138,69,61,108,218,103,428,128,472,263,57,179,243,218,77,220,383,525,168,242,144,268,140,148,114,196,114,50,67,65,186,557,447,418,104,347,276,276,120,59,136,40,296,149,255,442,327,148,277,279,80,122,257,45,568,223,89,114,125,71,54,368,273,113,67,75,105,393,171,105,109,179,298,163,277,142,46,118,152,103,44,80,488,139,317,105,263,140,192,313,342,81,246,434,110,55,139,158,203,84,150,193,451,191,153,357,128,337,216,202,88,426,87,145,118,278,156,176,125,212,118,183,229,73,393,177,158,193,201,143,191,229,100,129,281,397,153,488,187,101,95,97,190,170,176,66,201,347,204,268,156,341,71,150,134,39,87,119,77,151,102,131,201,293,119,68,196,339,185,120,194,110,291,165,138,43,200,106,143,270,158,65,37,59,115,117,100,207,275,159,115,222,170,115,137,167,74,197,159,137,68,112,237,81,489,111,113,227,762,220,160,81,271,107,110,186,98,104,389,284,58,163,237,198,72,213,68,119,107,76,466,365,590,217,106,386,92,114,123,281,105,193,64,393,194,157,113,48,150,68,178,113,135,233,214,295,125,230,220,60,171,242,82,76,187,164,146,63,109,73,84,112,101,211,251,275,194,373,149,69,267,167,32,277,259,58,216,240,162,284,198,276,155,109,87,364,124,108,200,78,124,159,158,194,202,87,48,177,60,218,253,165,230,128,73,178,259,256,278,427,114,189,104,64,197,169,275,97,223,120,143,24,146,253,85,403,75,76,44,256,338,162,112,153,245,174,209,286,131,89,376,215,304,56,243,138,52,90,168,165,162,174,408,416,80,58,259,491,162,309,174,155,522,134,281,277,222,119,449,78,91,176,279,412,128,185,51,76,95,179,207,38,255,256,171,51,148,133,53,107,69,187,173,47,57,96,741,186,193,396,48,70,288,97,243,136,379,181,110,142,45,88,250,361,218,69,111,144,175,345,203,151,116,95,275,218,420,291,183,181,29,89,234,113,173,143,171,128,165,120,282,63,235,37,82,374,174,94,49,469,94,350,139,587,273,204,94,145,78,696,125,65,221,413,207,119,256,65,151,132,198,507,202,74,233,314,346,278,94,257,278,137,109,123,173,25,174,270,264,283,148,205,428,300,194,120,251,335,110,122,267,198,409,80,92,203,565,92,123,135,107,280,128,137,192,127,122,131,108,168,137,201,293,108,452,371,66,105,35,132,86,344,117,117,99,194,244,241,81,299,70,81,119,400,145,381,140,82,151,132,141,196,270,103,113,126,411,75,94,19,77,113,210,60,348,210,260,63,236,170,98,41,98,163,156,294,140,185,149,258,228,73,131,271,104,113,237,163,80,132,113,139,242,271,246,243,86,215,127,205,177,510,180,99,65,239,88,136,107,120,41,124,342,558,159,80,41,278,84,240,140,242,55,152,303,274,250,74,40,100,207,186,284,121,119,383,141,420,123,124,105,126,180,70,171,187,266,91,104,260,526,155,172,330,225,206,163,77,150,213,52,310,381,76,217,524,53,48,173,174,130,205,187,166,87,47,274,222,141,182,195,90,108,95,128,456,421,108,188,120,196,324,313,395,70,113,276,209,311,123,252,153,878,35,49,139,82,143,74,98,140,103,157,134,133,39,158,71,48,146,163,122,169,143,70,188,277,232,48,75,345,44,215,175,174,128,220,223,64,100,171,166,130,133,166,269,207,68,94,246,155,100,329,296,163,189,419,84,328,68,100,146,155,166,74,113,778,96,350,88,136,127,257,275,431,351,140,224,196,68,172,356,306,316,101,121,134,222,122,131,194,153,192,286,260,269,59,178,32,207,94,216,201,194,221,63,156,139,91,217,241,255,209,109,266,202,57,163,201,190,93,86,232,401,99,121,37,232,228,98,502,260,175,112,254,525,83,435,158,111,106,191,170,243,143,440,118,212,248,258,273,110,386,444,121,117,120,229,71,162,122,385,277,33,391,197,57,220,359,219,373,131,117,29,68,174,83,40,276,111,101,342,170,427,48,393,127,65,122,159,182,198,111,184,115,127,375,47,163,166,98,33,197,168,133,172,44,248,231,178,180,86,154,253,98,163,240,120,175,60,78,79,381,127,88,211,169,254,68,149,209,431,109,153,45,141,58,754,2087,415,238,259,83,939,216,97,673,724,284,115,132,171,278,1081,320,261,216,53,111,209,179,245,370,191,281,305,133,377,194,393,215,199,284,455,306,402,357,436,344,267,120,222,86,65,423,79,125,327,348,107,226,130,135,274,248,125,307,262,323,684,274,466,274,170,196,196,810,875,360,221,712,233,137,148,58,308,135,143,215,917,125,283,146,266,154,168,329,678,888,189,449,193,354,341,362,320,434,180,546,542,141,413,67,578,426,204,556,157,295,131,456,363,275,549,538,659,165,287,387,456,218,266,294,1608,712,503,359,175,256,98,617,755,139,215,334,83,300,216,128,259,448,174,269,604,129,257,241,468,225,328,462,646,155,299,153,143,173,178,192,122,252,245,156,658,309,202,678,229,437,468,270,1611,1564,379,209,212,76,140,118,457,341,257,163,208,147,237,446,461,304,370,385,196,185,77,92,1163,241,113,432,185,165,242,221,228,114,218,375,235,272,141,238,100,183,80,271,410,407,257,257,193,202,440,79,165,1100,251,771,1037,143,187,450,223,400,621,318,127,608,119,235,83,380,1077,140,244,348,348,274,613,80,557,195,241,168,286,1385,424,183,126,616,111,225,61,1093,263,313,437,341,253,70,181,161,273,284,175,101,369,153,296,686,239,86,133,663,77,363,502,273,201,425,807,187,67,349,197,390,158,323,488,109,113,654,75,171,550,963,89,1000,109,444,471,180,516,449,404,268,128,313,379,119,345,441,553,92,763,372,548,140,338,368,392,199,183,305,332,63,201,70,490,287,102,91,329,368,213,93,636,173,253,154,118,166,289,321,127,278,217,324,665,440,299,163,154,225,372,224,71,308,177,373,187,283,111,309,725,288,334,517,154,147,638,144,531,640,193,628,92,273,243,302,367,102,599,133,125,203,728,166,439,1049,185,231,281,80,180,252,346,143,335,289,107,188,159,74,165,249,209,379,280,494,293,283,205,218,186,260,130,253,879,245,1204,783,196,317,526,367,143,196,143,234,354,236,204,257,358,279,180,312,280,217,386,146,387,136,723,172,341,97,915,275,302,174,109,267,88,438,494,327,318,236,369,111,124,307,204,510,99,2643,259,197,320,227,357,430,330,344,405,478,527,389,526,367,210,450,639,174,517,132,93,373,1261,183,260,620,251,117,251,159,225,298,448,379,141,62,146,174,333,389,624,129,218,493,488,283,785,87,104,212,498,332,1255,329,437,160,542,93,220,406,165,147,68,451,387,128,371,469,444,160,3613,476,360,498,267,388,75,557,506,414,115,325,553,391,266,251,301,497,69,567,602,503,3815,348,433,84,155,202,518,217,1015,340,480,505,226,461,181,211,97,209,120,628,198,429,200,674,330,142,299,272,238,1758,474,146,160,363,193,246,174,753,154,378,270,506,349,487,398,402,156,150,80,77,290,452,296,73,444,320,187,106,139,659,156,95,565,428,83,709,89,380,213,386,185,210,301,287,749,485,1104,229,206,91,243,284,151,178,602,999,410,743,281,123,285,501,430,196,370,99,351,530,61,202,351,88,238,366,255,167,107,404,736,198,196,184,93,201,618,382,284,268,200,656,198,481,174,355,399,568,223,114,131,171,132,342,201,285,110,2015,277,482,202,175,392,273,412,94,447,200,362,189,526,119,200,567,600,162,282,336,96,384,1096,548,166,243,424,230,332,342,136,127,269,346,168,91,258,429,390,382,316,70,666,117,699,476,593,336,235,168,70,362,186,175,241,440,238,331,495,623,114,75,408,1093,590,393,267,629,820,127,245,107,313,1572,196,494,421,151,148,278,129,393,173,277,286,396,59,1272,420,312,89,106,67,460,139,139,254,198,673,256,483,417,241,474,569,938,99,134,186,202,328,285,1035,164,147,299,140,157,410,386,407,73,175,566,579,336,861,155,238,417,137,84,245,405,596,88,434,102,375,271,606,216,231,59,456,745,343,529,595,459,183,145,148,374,311,230,432,390,258,261,177,108,123,334,301,320,284,500,364,497,380,292,175,136,107,250,209,245,219,298,401,138,254,235,116,230,605,739,87,292,327,102,274,485,249,394,354,448,245,311,434,111,641,547,142,75,490,286,327,208,165,320,118,705,137,62,115,532,479,156,109,66,208,327,554,312,340,205,238,270,127,739,182,249,183,306,152,435,118,169,280,209,250,165,163,180,144,528,594,292,184,340,166,323,128,216,111,498,437,179,308,403,254,207,283,564,466,464,111,187,132,673,359,466,783,215,109,529,556,781,232,138,275,265,411,138,356,462,82,306,172,480,480,820,167,139,428,449,158,210,304,952,423,414,126,544,420,83,772,182,375,922,313,428,438,135,324,263,651,191,146,328,230,106,119,369,358,745,584,266,150,480,442,92,201,438,444,138,490,77,544,455,263,184,258,296,244,211,248,125,143,328,257,447,121,700,195,294,366,275,709,276,88,717,343,217,88,471,372,230,82,533,248,178,321,212,256,329,108,162,258,336,328,181,280,262,1527,302,87,110,559,1118,201,516,171,396,221,558,163,198,492,178,126,112,350,457,164,303,584,709,133,643,246,262,424,333,223,289,1248,153,310,874,357,602,350,211,402,463,464,157,255,459,300,373,634,438,622,114,606,400,117,139,296,1627,247,229,322,321,171,183,97,284,97,146,159,956,545,169,156,737,791,154,137,192,259,209,206,465,463,304,100,254,384,293,261,284,362,328,491,1315,1379,158,251,228,259,174,488,228,391,304,255,352,430,585,666,281,211,2059,149,146,305,404,621,491,162,162,423,567,313,84,90,129,181,135,183,248,333,161,513,272,217,154,468,739,376,224,131,70,168,1205,259,600,425,348,769,261,370,423,97,512,346,97,662,95,326,1133,122,324,297,139,728,168,84,144,396,65,142,380,207,251,169,139,463,155,358,218,514,910,215,235,388,190,305,299,340,309,436,767,309,262,252,136,403,124,261,137,149,2003,444,139,226,1003,266,505,1185,273,316,343,111,95,423,293,178,302,775,276,178,74,466,503,187,246,273,656,314,447,910,289,247,157,265,316,101,183,440,275,189,225,431,518,378,449,474,948,432,193,259,265,544,665,94,1681,363,67,892,253,313,344,108,242,165,272,227,225,151,440,889,413,1217,509,350,155,332,109,305,131,222,182,143,434,503,311,399,890,194,305,208,61,281,571,321,333,97,445,196,465,284,338,744,150,460,274,184,284,624,431,573,256,268,235,116,163,81,108,292,467,232,192,296,197,81,214,1510,162,210,72,526,287,512,750,798,90,522,142,256,1031,209,905,233,1232,69,175,341,275,192,116,209,236,129,87,285,239,240,404,200,317,170,370,630,90,339,375,79,143,206,150,226,363,120,326,221,136,82,129,100,634,679,196,117,185,275,334,183,65,170,884,159,1074,445,310,263,298,250,519,415,1092,239,170,410,339,287,322,662,253,95,110,131,348,129,115,200,385,221,291,155,184,565,1923,469,181,211,176,293,1203,368,2935,308,342,166,200,82,184,355,327,292,240,99,79,186,268,72,412,79,432,219,197,582,623,723,137,1705,996,205,424,764,483,539,380,159,1421,100,392,446,198,210,218,61,139,241,702,233,161,294,258,219,220,90,359,252,351,140,268,130,630,826,155,113,319,381,470,275,89,354,529,144,411,526,738,266,165,148,602,1372,331,551,283,336,176,87,529,408,64,313,144,104,69,118,185,468,184,256,174,281,299,148,154,219,178,291,221,658,248,324,1019,505,326,143,147,101,244,2562,229,133,61,485,237,216,141,334,166,314,93,516,284,329,397,453,164,757,247,282,416,595,186,432,161,720,354,174,168,762,346,1365,175,581,291,55,82,472,444,275,296,149,379,202,182,107,340,368,530,419,84,426,152,118,161,528,193,311,184,482,82,398,242,405,84,96,217,100,674,142,359,212,65,297,222,166,287,147,166,295,89,148,543,84,1055,170,363,234,238,186,267,596,386,511,615,396,720,102,132,155,1236,267,154,358,119,1040,205,229,397,530,279,248,401,201,369,146,598,284,419,490,857,656,113,196,154,234,116,162,280,806,82,111,669,252,579,100,408,189,195,570,132,320,357,506,318,160,401,215,239,389,238,70,284,218,263,127,273,187,190,173,126,133,306,425,337,558,359,298,228,335,491,119,202,281,537,699,1379,264,421,636,1471,182,298,242,436,609,615,488,323,467,288,74,170,1143,215,181,559,351,512,185,541,169,227,240,284,381,572,1132,130,221,916,120,370,246,153,493,529,57,576,802,344,547,127,536,94,643,106,322,278,108,280,105,192,190,384,198,211,160,168,158,153,389,90,411,468,316,225,136,376,363,242,318,213,361,223,414,233,858,150,262,752,300,423,284,135,201,355,231,433,101,210,1019,204,280,397,115,411,635,151,162,447,173,242,80,49,115,471,109,192,355,293,329,897,239,201,134,460,1767,123,182,211,400,317,160,400,350,169,179,225,242,213,540,78,301,254,611,332,201,279,619,151,339,303,525,488,256,82,114,1233,356,519,191,121,329,909,173,177,418,613,236,294,269,87,757,85,182,921,445,121,230,322,774,78,184,141,140,121,174,312,156,172,172,321,231,175,287,218,360,150,198,156,788,261,127,173,424,256,282,106,732,554,349,874,69,392,257,193,309,307,115,366,99,1194,230,1144,110,536,261,358,264,169,103,80,152,287,375,307,226,100,398,343,92,234,604,196,243,215,307,283,132,247,349,160,154,182,837,301,122,136,148,107,86,133,680,190,211,416,750,100,221,154,91,108,302,175,289,282,598,350,315,345,200,80,484,128,253,260,226,227,273,337,336,677,106,458,222,95,144,228,86,243,156,192,343,184,81,291,272,167,216,222,239,937,314,281,784,230,222,193,112,817,137,317,142,217,346,186,460,621,92,2332,722,1546,168,90,591,974,412,107,271,454,402,539,560,312,658,317,406,201,373,475,99,287,91,428,225,412,608,256,485,454,448,140,344,288,537,148,679,304,687,104,197,188,254,316,317,740,235,245,179,247,294,86,249,235,393,76,626,418,279,105,243,436,249,130,179,120,430,211,145,296,102,106,116,184,351,415,391,95,747,1082,202,274,910,1161,176,127,97,511,180,407,406,372,443,129,250,219,281,218,658,139,172,244,394,321,865,310,694,284,172,507,216,101,190,113,222,323,245,172,117,759,112,318,320,250,338,87,404,255,327,345,401,96,259,356,354,114,109,215,239,162,723,1104,324,179,274,291,952,300,178,350,228,108,493,196,662,277,229,349,61,567,557,497,170,393,176,490,73,166,407,445,285,56,852,343,461,62,209,82,110,601,240,183,146,119,278,125,127,273,512,702,402,177,88,278,270,198,309,186,305,217,205,233,219,129,136,487,169,77,169,613,113,451,145,334,362,364,356,772,252,72,83,286,265,893,90,452,246,134,135,372,118,252,94,206,92,322,279,381,291,301,452,142,228,165,81,74,508,114,231,424,210,165,240,137,393,506,562,126,663,294,369,527,160,216,136,106,286,192,289,277,166,369,104,1207,136,155,449,66,168,202,319,172,151,519,131,508,163,232,234,172,215,590,863,219,150,65,282,254,243,293,651,259,183,331,183,93,270,4703,477,645,210,485,507,148,254,193,238,106,537,72,89,448,211,191,399,91,241,382,83,134,189,219,291,390,177,198,181,299,206,162,347,206,319,374,571,325,352,1447,200,122,317,313,395,90,404,367,208,464,265,198,298,406,169,242,373,343,391,553,104,449,1545,162,217,295,272,194,167,83,520,331,1502,773,158,490,321,82,147,133,462,155,281,291,152,320,147,483,411,201,260,319,494,271,280,1501,522,366,360,415,261,63,209,356,122,412,462,287,334,106,242,248,107,795,73,257,164,241,209,174,174,203,210,911,209,246,96,399,332,187,409,111,254,645,242,91,211,544,566,190,353,212,262,235,357,328,215,232,610,406,140,965,237,156,466,647,444,262,471,260,298,390,222,90,1101,336,438,123,389,174,479,326,267,169,227,408,154,766,128,186,404,85,212,356,440,248,216,407,158,144,254,298,117,127,989,477,459,111,342,93,404,388,81,441,293,180,257,322,2480,181,767,138,159,215,207,240,114,550,283,635,96,320,177,401,222,288,359,274,253,180,189,280,155,159,362,579,173,237,516,151,94,124,79,93,195,156,92,588,296,453,137,445,130,93,226,247,674,187,305,478,126,638,381,286,152,772,517,65,273,336,84,462,284,171,134,276,964,97,401,165,87,138,194,113,107,176,136,173,287,105,203,318,429,82,219,158,385,78,147,116,143,399,112,378,350,93,113,962,581,61,613,386,175,237,73,986,62,662,267,247,178,345,261,588,743,247,386,769,143,145,534,328,176,240,1135,390,203,127,539,421,114,225,179,144,110,331,131,265,552,392,362,279,596,103,346,304,587,109,313,470,141,360,198,583,128,465,367,705,640,374,1792,187,113,76,340,289,222,329,339,435,109,60,886,86,818,271,241,1058,259,174,142,189,211,278,227,496,940,512,77,130,1380,369,255,377,205,213,77,285,56,450,208,292,237,169,382,931,458,1398,462,180,631,299,128,197,321,464,135,267,399,228,272,119,58,207,145,135,158,69,134,498,438,334,195,325,441,320,382,257,83,125,200,125,362,347,407,165,136,97,351,389,60,356,67,272,144,407,2377,97,356,689,346,70,212,295,180,812,226,245,648,250,301,157,232,510,315,129,357,65,197,143,308,955,301,805,469,114,546,151,320,229,120,76,154,392,170,110,140,253,469,189,320,885,320,445,636,106,288,299,139,214,348,75,1011,120,219,244,122,270,636,176,321,229,225,228,262,325,170,127,900,241,56,1776,146,428,229,508,420,218,205,481,274,509,1195,308,323,277,402,176,1112,279,95,185,184,280,185,149,228,374,141,724,340,75,167,387,614,122,263,287,470,280,320,257,434,166,361,243,194,125,322,1556,227,103,334,119,632,78,466,118,530,372,169,132,393,335,283,277,182,211,99,44,279,218,286,157,277,335,155,224,72,130,423,435,592,404,128,69,119,356,310,963,403,237,450,109,370,1038,443,216,807,435,208,305,524,191,288,301,189,78,314,249,584,394,117,129,331,304,134,219,116,245,78,197,116,129,271,566,164,378,296,473,321,280,203,99,119,104,517,88,622,567,354,121,493,313,192,198,331,196,142,187,304,63,468,724,438,644,176,262,796,972,171,229,347,107,263,393,505,277,74,71,817,501,185,159,359,268,648,95,585,125,118,439,607,500,766,478,1157,585,550,161,384,291,1074,135,251,440,453,257,414,72,94,427,348,123,159,269,79,277,131,509,218,386,145,411,549,510,61,276,724,220,99,143,130,437,225,477,698,311,352,137,634,745,541,92,416,143,257,245,285,199,228,227,254,443,75,328,68,308,186,237,144,66,218,216,400,443,129,384,241,316,346,150,246,171,105,245,228,136,163,368,189,107,286,67,509,130,566,441,122,861,127,571,619,127,121,457,471,502,397,670,274,117,315,207,185,169,185,459,687,768,648,543,89,142,165,333,217,213,146,255,325,289,443,288,289,809,306,619,115,857,115,187,660,2578,328,84,578,602,146,385,486,891,930,185,259,386,178,538,474,516,303,424,136,256,678,196,212,494,256,130,255,360,548,370,484,100,127,123,245,199,304,177,391,147,378,112,255,987,191,159,460,557,383,250,366,395,322,252,531,128,99,153,293,434,298,151,293,215,280,92,320,152,376,503,201,578,424,121,374,374,163,232,174,207,219,391,329,478,97,351,191,435,567,140,139,525,450,141,370,305,82,345,916,402,412,117,303,488,246,340,666,680,194,298,599,289,251,249,294,613,248,735,165,1159,214,134,1170,61,145,359,161,823,169,845,417,126,388,254,124,466,637,703,877,1250,214,427,96,292,60,303,449,449,395,302,150,155,222,335,259,129,719,326,119,352,298,678,574,983,539,841,652,179,233,159,105,715,144,224,294,282,96,556,368,176,99,175,293,757,242,482,277,155,429,292,472,164,861,251,169,221,656,170,293,228,271,266,515,228,515,268,162,108,227,825,342,535,2297,357,264,1094,197,70,193,570,592,718,884,120,1651,349,136,398,770,474,872,89,220,430,160,299,129,131,238,289,110,271,139,183,127,106,377,93,215,288,287,392,246,433,284,411,315,360,344,581,311,112,81,564,536,437,274,160,160,220,436,336,106,231,326,239,209,235,75,405,205,165,467,270,81,114,509,179,366,177,309,84,351,241,124,295,453,266,433,144,365,359,115,1224,141,287,139,262,177,130,547,244,294,215,276,254,468,165,73,67,140,307,89,239,174,96,507,112,424,202,741,134,166,345,91,180,107,136,124,79,143,345,55,594,568,222,327,635,116,80,231,1727,348,344,151,137,138,114,446,465,123,634,678,250,300,401,498,373,158,249,236,184,231,137,312,342,139,551,393,136,296,515,625,341,290,73,109,369,170,307,150,299,622,486,409,141,455,348,68,592,171,659,250,169,323,448,87,389,123,375,104,1365,128,78,1270,280,2153,825,79,460,537,125,260,127,58,259,1071,358,215,458,305,113,186,405,346,503,411,201,368,279,457,79,746,123,326,671,415,170,267,147,454,295,234,70,547,300,865,269,220,131,257,513,464,163,84,197,1878,248,305,218,344,497,277,133,159,262,408,511,109,389,223,303,141,533,148,150,205,477,401,299,489,333,249,131,162,532,275,541,115,215,85,75,201,82,124,180,95,223,114,458,1968,842,361,297,261,601,388,452,256,127,152,170,164,258,382,138,490,1611,147,71,264,233,1001,552,963,178,209,202,422,154,849,124,974,155,1565,1299,133,162,209,402,526,365,355,195,692,439,390,98,305,362,653,202,370,448,229,120,225,591,358,278,401,395,1125,273,242,602,66,774,184,73,754,200,484,78,252,201,316,359,166,489,118,332,416,445,445,538,169,405,138,72,556,258,221,84,246,82,342,139,647,416,383,215,210,87,88,97,285,227,239,451,656,243,233,296,104,140,197,198,157,517,242,209,201,190,349,96,389,290,411,318,232,738,139,274,313,227,215,504,364,253,216,370,458,459,87,249,557,258,196,219,89,344,529,459,178,97,169,300,170,122,332,229,145,930,185,1025,344,188,278,273,123,383,410,525,216,1285,358,352,95,321,113,230,228,391,2251,395,106,67,267,68,699,228,167,75,115,901,230,1483,355,618,199,586,210,175,133,640,281,151,74,149,232,431,887,122,776,135,307,108,142,120,150,112,253,197,419,1502,264,768,206,141,790,112,102,199,166,263,649,559,226,865,202,728,213,173,622,282,318,105,578,1038,531,100,80,491,104,327,64,553,834,160,508,57,180,983,85,435,382,316,508,319,615,222,79,265,318,470,258,939,323,247,63,288,170,171,450,266,164,419,395,596,1160,465,738,171,176,364,281,81,362,111,368,486,238,269,156,276,243,193,144,179,134,546,355,204,172,250,293,287,769,323,148,157,267,248,120,368,176,79,512,96,537,505,483,269,239,208,194,211,90,277,623,311,61,342,163,169,205,82,265,156,299,228,552,276,448,94,873,134,106,185,154,97,412,363,252,209,121,247,472,945,100,405,314,285,138,285,415,121,414,463,563,189,487,1102,981,650,241,129,196,165,178,133,206,368,106,582,53,432,464,231,241,90,291,287,315,279,482,298,303,83,235,244,391,579,146,140,320,138,210,204,322,127,182,314,1358,225,100,355,224,113,366,517,303,289,285,339,478,751,312,554,70,137,120,287,156,69,260,260,106,56,171,264,95,1533,427,236,421,135,528,259,278,299,186,117,407,383,491,478,128,344,176,323,130],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Length of Quote\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Distribution of Quote Lengths\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('b2e75492-b41a-4dac-9c9c-b6a86121384a');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Calculate quantiles\nquantiles = df['quote_length'].quantile([0.75, 0.9, 0.95])\nprint(quantiles)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T22:19:57.021392Z","iopub.execute_input":"2025-01-17T22:19:57.021713Z","iopub.status.idle":"2025-01-17T22:19:57.034275Z","shell.execute_reply.started":"2025-01-17T22:19:57.021684Z","shell.execute_reply":"2025-01-17T22:19:57.033320Z"}},"outputs":[{"name":"stdout","text":"0.75    365.0\n0.90    544.0\n0.95    722.5\nName: quote_length, dtype: float64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"\n\n- Distilbert should be less energy consuming, it has less params \n- Lower case so less params ","metadata":{}},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T22:20:01.565593Z","iopub.execute_input":"2025-01-17T22:20:01.565943Z","iopub.status.idle":"2025-01-17T22:20:18.792471Z","shell.execute_reply.started":"2025-01-17T22:20:01.565914Z","shell.execute_reply":"2025-01-17T22:20:18.791797Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a23b7c4940264bef9b0c2359313302eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc72af748d254aafba67c82067947cef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a373f432ddf546d1965e69049ba5ac13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8519333548bb412fa70ecd204b8c842b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f19dea61e0794a68a0fccabdcf953702"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"**Understanding the Message**\nPre-trained Model Weights: When you load a model like bert-base-cased, it comes with weights that have been pre-trained on a large corpus of text data. These weights are primarily associated with the BERT model's architecture responsible for understanding the language patterns (e.g., layers that handle token embeddings, attention mechanisms).\n\n**New Task-Specific Weights**: However, since BertForSequenceClassification adapts BERT to a classification task by adding a classifier on top of the base BERT model, the weights for this classifier (classifier.bias, classifier.weight) are not part of the original pre-trained model. They need to be trained (initialized) for your specific classification task.\n\n**What This Means for Training**\nInitialization: The classifier layers weights are initialized randomly and need to be trained (i.e., fine-tuned) on a dataset specific to your classification task. This fine-tuning process adapts the general language understanding capabilities of BERT to the nuances of your specific classification problem.\n\n**Necessity of Training**: This message is a reminder that although the base BERT layers are pre-trained, the classifier's weights are new and untrained. You must train the model on a downstream task (like your text classification) to adjust these weights meaningfully for predictions and inference.\n\n**Is Your Code Handling This?**\nIn the code you provided, you are indeed setting up and executing this necessary training:\n\n*Data Preparation*: You encode your text data, prepare labels, and set up DataLoader instances for both training and validation datasets.\n\n*Training Loop*: You run a training loop where:\n\nYou perform a forward pass where the model calculates predictions and, if labels are provided (which they are), computes the loss using the internally managed cross-entropy criterion.\nYou perform backpropagation (loss.backward()) and an optimizer step (optimizer.step()) to update the classifiers weights based on the computed loss.\nYou reset gradients for the next iteration with optimizer.zero_grad().\n\n*Validation Step*: After each epoch, you evaluate the model on a validation set to monitor performance improvements and generalize the model's ability beyond the training data.","metadata":{}},{"cell_type":"code","source":"# Dataset class\nclass QuotesDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Function to encode the data\ndef encode_data(tokenizer, texts, labels, max_length):\n    encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n    return QuotesDataset(encodings, labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T22:20:29.676937Z","iopub.execute_input":"2025-01-17T22:20:29.677449Z","iopub.status.idle":"2025-01-17T22:20:29.684739Z","shell.execute_reply.started":"2025-01-17T22:20:29.677411Z","shell.execute_reply":"2025-01-17T22:20:29.683703Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Validation\n\n- During validation, for each batch, the model outputs logits (i.e., raw model outputs before applying an activation function like softmax).\n- The logits are then converted into actual predictions using the torch.argmax function, which selects the index of the highest value in each set of logits across the specified dimension (dim=-1 means along the last dimension, effectively choosing the predicted class).\n- These predictions and the true labels from the validation dataset batches are collected into lists: all_predictions and all_true_labels.","metadata":{}},{"cell_type":"code","source":"\"\"\"\n# subset of the dataset for testing\nsmall_dataset = df.sample(frac=1, random_state=42).reset_index(drop=True)\nsmall_dataset = small_dataset.iloc[:1000]\n\ntexts = small_dataset[\"quote\"].to_list()\nlabels = small_dataset[\"label_int\"].to_list()\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:06:23.078201Z","iopub.execute_input":"2025-01-17T19:06:23.079104Z","iopub.status.idle":"2025-01-17T19:06:23.093898Z","shell.execute_reply.started":"2025-01-17T19:06:23.079024Z","shell.execute_reply":"2025-01-17T19:06:23.092501Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"texts = df[\"quote\"].to_list()\nlabels = df[\"label_int\"].to_list()\n\n# dict for mapping label indices to names \nlabel_dict = df[['label_int', 'label']].drop_duplicates().set_index('label_int')['label'].to_dict()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T22:20:33.564227Z","iopub.execute_input":"2025-01-17T22:20:33.564542Z","iopub.status.idle":"2025-01-17T22:20:33.577297Z","shell.execute_reply.started":"2025-01-17T22:20:33.564522Z","shell.execute_reply":"2025-01-17T22:20:33.576587Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.33, random_state=42)\n\n# Encode the data\nmax_length = 365  # 75% percentile of all quote lengths\ntrain_dataset = encode_data(tokenizer, X_train, y_train, max_length)\nval_dataset = encode_data(tokenizer, X_test, y_test, max_length)\n\n# Data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\n# Training settings\nlr=2e-5   # need to experiment with this\nepochs = 3\n\n\noptimizer = AdamW(model.parameters(), lr=lr)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Training loop\nfor epoch in range(epochs):\n    model.train()\n    for batch in train_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch) # Forward pass; model calculates loss if 'labels' are included.\n        loss = outputs.loss   # Access the computed loss.\n        loss.backward()       # Compute gradients.\n        optimizer.step()      # Update model parameters.\n        optimizer.zero_grad() # Clear gradients for the next training step.\n        outputs = model(**batch)       \n    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n\n    # Validation \n    model.eval()\n    all_predictions = []\n    all_true_labels = []\n    \n    for batch in val_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(batch['labels'].cpu().numpy())\n\n    # Calculate F1 scores\n    f1_scores_per_class = f1_score(all_true_labels, all_predictions, average=None)\n    weighted_f1_score = f1_score(all_true_labels, all_predictions, average='weighted')\n\n    # Printing F1 scores with corresponding class names\n    for index, score in enumerate(f1_scores_per_class):\n        print(f\"Class: {label_dict[index]}, F1 Score: {score:.4f}\")\n    print(f\"Weighted F1 Score: {weighted_f1_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T22:20:38.848111Z","iopub.execute_input":"2025-01-17T22:20:38.848430Z","iopub.status.idle":"2025-01-17T22:30:14.275420Z","shell.execute_reply.started":"2025-01-17T22:20:38.848404Z","shell.execute_reply":"2025-01-17T22:30:14.274448Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-10-d10002713a8a>:8: UserWarning:\n\nTo copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.8911074995994568\nClass: 0_not_relevant, F1 Score: 0.6880\nClass: 1_not_happening, F1 Score: 0.7035\nClass: 2_not_human, F1 Score: 0.5650\nClass: 3_not_bad, F1 Score: 0.4519\nClass: 4_solutions_harmful_unnecessary, F1 Score: 0.6394\nClass: 5_science_unreliable, F1 Score: 0.5835\nClass: 6_proponents_biased, F1 Score: 0.5537\nClass: 7_fossil_fuels_needed, F1 Score: 0.5765\nWeighted F1 Score: 0.6165\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-10-d10002713a8a>:8: UserWarning:\n\nTo copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.5752794742584229\nClass: 0_not_relevant, F1 Score: 0.7020\nClass: 1_not_happening, F1 Score: 0.7680\nClass: 2_not_human, F1 Score: 0.6667\nClass: 3_not_bad, F1 Score: 0.6532\nClass: 4_solutions_harmful_unnecessary, F1 Score: 0.6655\nClass: 5_science_unreliable, F1 Score: 0.5695\nClass: 6_proponents_biased, F1 Score: 0.5755\nClass: 7_fossil_fuels_needed, F1 Score: 0.5876\nWeighted F1 Score: 0.6585\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-10-d10002713a8a>:8: UserWarning:\n\nTo copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.769638180732727\nClass: 0_not_relevant, F1 Score: 0.7442\nClass: 1_not_happening, F1 Score: 0.7539\nClass: 2_not_human, F1 Score: 0.6928\nClass: 3_not_bad, F1 Score: 0.6222\nClass: 4_solutions_harmful_unnecessary, F1 Score: 0.6730\nClass: 5_science_unreliable, F1 Score: 0.5984\nClass: 6_proponents_biased, F1 Score: 0.6767\nClass: 7_fossil_fuels_needed, F1 Score: 0.5444\nWeighted F1 Score: 0.6828\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}