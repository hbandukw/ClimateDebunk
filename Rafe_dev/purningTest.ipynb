{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10605139,"sourceType":"datasetVersion","datasetId":6564816},{"sourceId":245231,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":209517,"modelId":231211}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install codecarbon","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:45.369803Z","iopub.execute_input":"2025-01-30T17:27:45.370144Z","iopub.status.idle":"2025-01-30T17:27:48.757806Z","shell.execute_reply.started":"2025-01-30T17:27:45.370117Z","shell.execute_reply":"2025-01-30T17:27:48.756802Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: codecarbon in /usr/local/lib/python3.10/dist-packages (2.8.3)\nRequirement already satisfied: arrow in /usr/local/lib/python3.10/dist-packages (from codecarbon) (1.3.0)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon) (8.1.7)\nRequirement already satisfied: fief-client[cli] in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.20.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.2.2)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.21.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon) (9.0.0)\nRequirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from codecarbon) (11.4.1)\nRequirement already satisfied: questionary in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.1.0)\nRequirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from codecarbon) (3.12.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.32.3)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from codecarbon) (13.9.4)\nRequirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.15.1)\nRequirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon) (2.8.2)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon) (2.9.0.20241206)\nRequirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\nRequirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\nRequirement already satisfied: yaspin in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (3.1.0)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (1.26.4)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (2024.2)\nRequirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from questionary->codecarbon) (3.0.48)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2024.12.14)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (2.18.0)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (4.12.2)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->codecarbon) (1.5.4)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.7)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.14.0)\nRequirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.10/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->codecarbon) (2.4.1)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.13)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\nRequirement already satisfied: termcolor<2.4.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.2.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->codecarbon) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->codecarbon) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas->codecarbon) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas->codecarbon) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas->codecarbon) (2024.2.0)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertConfig\nfrom sklearn.metrics import f1_score, confusion_matrix, balanced_accuracy_score, precision_score, recall_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom torch.optim import AdamW, lr_scheduler\nimport shutil\nimport zipfile\nimport copy\nfrom torch.nn.utils import prune\nimport io\nfrom codecarbon import EmissionsTracker\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:48.759272Z","iopub.execute_input":"2025-01-30T17:27:48.759499Z","iopub.status.idle":"2025-01-30T17:27:48.766286Z","shell.execute_reply.started":"2025-01-30T17:27:48.759478Z","shell.execute_reply":"2025-01-30T17:27:48.765562Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"model_path = '/kaggle/input/baseline/pytorch/default/1/distilbert_trained.pth'\nconfig = DistilBertConfig.from_pretrained('distilbert-base-uncased', num_labels=8)\nmodel = DistilBertForSequenceClassification(config)\n\nmodel.load_state_dict(torch.load(model_path))\n\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:48.768254Z","iopub.execute_input":"2025-01-30T17:27:48.768524Z","iopub.status.idle":"2025-01-30T17:27:50.260188Z","shell.execute_reply.started":"2025-01-30T17:27:48.768487Z","shell.execute_reply":"2025-01-30T17:27:50.259483Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-19-6a60583ab53d>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): DistilBertSdpaAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=8, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"def apply_pruning(model, pruning_params):\n    for name, module in model.named_modules():\n        if name in pruning_params:\n            if hasattr(module, 'weight'):\n                prune.l1_unstructured(module, name='weight', amount=pruning_params[name])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:50.261256Z","iopub.execute_input":"2025-01-30T17:27:50.261537Z","iopub.status.idle":"2025-01-30T17:27:50.265418Z","shell.execute_reply.started":"2025-01-30T17:27:50.261511Z","shell.execute_reply":"2025-01-30T17:27:50.264514Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"lin1_layer0_pruning = 0.2017953262091607\nlin2_layer0_pruning = 0.15729525440967862\nlin1_layer1_pruning = 0.12969848850621088\nlin2_layer1_pruning = 0.454859759610882\nlin1_layer2_pruning = 0.2310579033256247\nlin2_layer2_pruning = 0.1607487810536109\nlin1_layer3_pruning = 0.22990726915583418\nlin2_layer3_pruning = 0.29273042218157586\nlin1_layer4_pruning = 0.44861219131635766\nlin2_layer4_pruning = 0.23703770072386673\nlin1_layer5_pruning = 0.45099619043007\nlin2_layer5_pruning = 0.4751512722238028","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:50.266304Z","iopub.execute_input":"2025-01-30T17:27:50.266540Z","iopub.status.idle":"2025-01-30T17:27:50.277801Z","shell.execute_reply.started":"2025-01-30T17:27:50.266521Z","shell.execute_reply":"2025-01-30T17:27:50.277112Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"pruning_params = {\n    'distilbert.transformer.layer.0.ffn.lin1': 0.2017953262091607,\n    'distilbert.transformer.layer.0.ffn.lin2': 0.15729525440967862,\n    'distilbert.transformer.layer.1.ffn.lin1': 0.12969848850621088,\n    'distilbert.transformer.layer.1.ffn.lin2': 0.454859759610882,\n    'distilbert.transformer.layer.2.ffn.lin1': 0.2310579033256247,\n    'distilbert.transformer.layer.2.ffn.lin2': 0.1607487810536109,\n    'distilbert.transformer.layer.3.ffn.lin1': 0.22990726915583418,\n    'distilbert.transformer.layer.3.ffn.lin2': 0.29273042218157586,\n    'distilbert.transformer.layer.4.ffn.lin1': 0.44861219131635766,\n    'distilbert.transformer.layer.4.ffn.lin2': 0.23703770072386673,\n    'distilbert.transformer.layer.5.ffn.lin1': 0.45099619043007,\n    'distilbert.transformer.layer.5.ffn.lin2': 0.4751512722238028\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:50.278697Z","iopub.execute_input":"2025-01-30T17:27:50.278929Z","iopub.status.idle":"2025-01-30T17:27:50.289626Z","shell.execute_reply.started":"2025-01-30T17:27:50.278905Z","shell.execute_reply":"2025-01-30T17:27:50.288967Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# config = DistilBertConfig.from_pretrained('distilbert-base-uncased', num_labels=8)\n# model = DistilBertForSequenceClassification(config)\n# model.load_state_dict(torch.load(model_path))\n# model.to(device)\n\napply_pruning(model, pruning_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:50.290536Z","iopub.execute_input":"2025-01-30T17:27:50.290841Z","iopub.status.idle":"2025-01-30T17:27:50.341437Z","shell.execute_reply.started":"2025-01-30T17:27:50.290814Z","shell.execute_reply":"2025-01-30T17:27:50.340652Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def validate_model(model, val_loader, device):\n    # Ensure only one tracker instance runs at a time\n    tracker = EmissionsTracker(allow_multiple_runs=True)\n    tracker.start()\n\n    model.eval()\n    val_loss = 0\n    correct_val = 0\n    total_val = 0\n    all_predictions = []\n    all_true_labels = []\n\n    try:\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                outputs = model(**batch)\n                val_loss += outputs.loss.item()\n                predictions = torch.argmax(outputs.logits, dim=-1)\n                all_predictions.extend(predictions.cpu().numpy())\n                all_true_labels.extend(batch['labels'].cpu().numpy())\n                correct_val += (predictions == batch['labels']).sum().item()\n                total_val += batch['labels'].size(0)\n        average_val_loss = val_loss / len(val_loader)\n        accuracy = correct_val / total_val\n\n    finally:\n        emissions = tracker.stop()\n        if emissions:\n            total_energy_used = getattr(emissions, 'energy_consumed', 0)\n        else:\n            total_energy_used = 0  # Default to 0 if emissions data is not available\n\n    return average_val_loss, accuracy, all_predictions, all_true_labels, total_energy_used","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:50.342266Z","iopub.execute_input":"2025-01-30T17:27:50.342530Z","iopub.status.idle":"2025-01-30T17:27:50.348500Z","shell.execute_reply.started":"2025-01-30T17:27:50.342503Z","shell.execute_reply":"2025-01-30T17:27:50.347850Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/test-parquet/test-00000-of-00001.parquet\")\ndf['label_int'] = df['label'].str.split(\"_\").str[0].astype('int')\n\ntexts = df[\"quote\"].to_list()\nlabels = df[\"label_int\"].to_list()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:50.350409Z","iopub.execute_input":"2025-01-30T17:27:50.350628Z","iopub.status.idle":"2025-01-30T17:27:50.376934Z","shell.execute_reply.started":"2025-01-30T17:27:50.350600Z","shell.execute_reply":"2025-01-30T17:27:50.376066Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\nMAX_LENGTH = 365\n\n# Dataset and DataLoader preparation\nclass QuotesDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ndef encode_data(tokenizer, texts, labels, max_length):\n    try:\n        if isinstance(texts, pd.Series):\n            texts = texts.tolist()\n        if isinstance(labels, pd.Series):\n            labels = labels.tolist()\n            \n        encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n        return QuotesDataset(encodings, labels)\n\n    except Exception as e:\n        print(f\"Error during tokenization: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:50.377866Z","iopub.execute_input":"2025-01-30T17:27:50.378092Z","iopub.status.idle":"2025-01-30T17:27:50.585141Z","shell.execute_reply.started":"2025-01-30T17:27:50.378073Z","shell.execute_reply":"2025-01-30T17:27:50.584273Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"val_dataset = encode_data(tokenizer, texts, labels, MAX_LENGTH)\nval_loader = DataLoader(val_dataset, batch_size= 16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:50.585955Z","iopub.execute_input":"2025-01-30T17:27:50.586166Z","iopub.status.idle":"2025-01-30T17:27:52.089469Z","shell.execute_reply.started":"2025-01-30T17:27:50.586148Z","shell.execute_reply":"2025-01-30T17:27:52.088852Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"val_loss, val_accuracy, all_predictions, all_true_labels, emissions = validate_model(model, val_loader, device)\nprint(val_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:27:52.090204Z","iopub.execute_input":"2025-01-30T17:27:52.090489Z","iopub.status.idle":"2025-01-30T17:28:08.564933Z","shell.execute_reply.started":"2025-01-30T17:27:52.090459Z","shell.execute_reply":"2025-01-30T17:28:08.564190Z"}},"outputs":[{"name":"stderr","text":"[codecarbon WARNING @ 17:27:52] Multiple instances of codecarbon are allowed to run at the same time.\n[codecarbon INFO @ 17:27:52] [setup] RAM Tracking...\n[codecarbon INFO @ 17:27:52] [setup] CPU Tracking...\n[codecarbon WARNING @ 17:27:52] No CPU tracking mode found. Falling back on CPU constant mode. \n Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n\n[codecarbon WARNING @ 17:27:53] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n[codecarbon INFO @ 17:27:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n[codecarbon INFO @ 17:27:53] [setup] GPU Tracking...\n[codecarbon INFO @ 17:27:53] Tracking Nvidia GPU via pynvml\n[codecarbon INFO @ 17:27:53] >>> Tracker's metadata:\n[codecarbon INFO @ 17:27:53]   Platform system: Linux-6.6.56+-x86_64-with-glibc2.35\n[codecarbon INFO @ 17:27:53]   Python version: 3.10.12\n[codecarbon INFO @ 17:27:53]   CodeCarbon version: 2.8.3\n[codecarbon INFO @ 17:27:53]   Available RAM : 31.351 GB\n[codecarbon INFO @ 17:27:53]   CPU count: 4\n[codecarbon INFO @ 17:27:53]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n[codecarbon INFO @ 17:27:53]   GPU count: 2\n[codecarbon INFO @ 17:27:53]   GPU model: 2 x Tesla T4\n[codecarbon INFO @ 17:27:56] Saving emissions data to file /kaggle/working/emissions.csv\n<ipython-input-26-2d9dfced9ac1>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n[codecarbon INFO @ 17:28:08] Energy consumed for RAM : 0.000040 kWh. RAM Power : 11.756441116333008 W\n[codecarbon INFO @ 17:28:08] Energy consumed for all CPUs : 0.000143 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 17:28:08] Energy consumed for all GPUs : 0.000263 kWh. Total GPU Power : 77.96127960827428 W\n[codecarbon INFO @ 17:28:08] 0.000445 kWh of electricity used since the beginning.\n","output_type":"stream"},{"name":"stdout","text":"0.977850697292863\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"model_path = '/kaggle/input/baseline/pytorch/default/1/distilbert_trained.pth'\nconfig = DistilBertConfig.from_pretrained('distilbert-base-uncased', num_labels=8)\nmodel1 = DistilBertForSequenceClassification(config)\n\nmodel1.load_state_dict(torch.load(model_path))\n\nmodel1.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:28:36.041669Z","iopub.execute_input":"2025-01-30T17:28:36.041965Z","iopub.status.idle":"2025-01-30T17:28:37.393227Z","shell.execute_reply.started":"2025-01-30T17:28:36.041943Z","shell.execute_reply":"2025-01-30T17:28:37.392308Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-29-9b7a7d9ce86c>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model1.load_state_dict(torch.load(model_path))\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): DistilBertSdpaAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=8, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"val_loss, val_accuracy, all_predictions, all_true_labels, emissions = validate_model(model1, val_loader, device)\nprint(val_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:29:04.467111Z","iopub.execute_input":"2025-01-30T17:29:04.467448Z","iopub.status.idle":"2025-01-30T17:29:20.565175Z","shell.execute_reply.started":"2025-01-30T17:29:04.467408Z","shell.execute_reply":"2025-01-30T17:29:20.564276Z"}},"outputs":[{"name":"stderr","text":"[codecarbon WARNING @ 17:29:04] Multiple instances of codecarbon are allowed to run at the same time.\n[codecarbon INFO @ 17:29:04] [setup] RAM Tracking...\n[codecarbon INFO @ 17:29:04] [setup] CPU Tracking...\n[codecarbon WARNING @ 17:29:04] No CPU tracking mode found. Falling back on CPU constant mode. \n Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n\n[codecarbon WARNING @ 17:29:05] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n[codecarbon INFO @ 17:29:05] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n[codecarbon INFO @ 17:29:05] [setup] GPU Tracking...\n[codecarbon INFO @ 17:29:05] Tracking Nvidia GPU via pynvml\n[codecarbon INFO @ 17:29:05] >>> Tracker's metadata:\n[codecarbon INFO @ 17:29:05]   Platform system: Linux-6.6.56+-x86_64-with-glibc2.35\n[codecarbon INFO @ 17:29:05]   Python version: 3.10.12\n[codecarbon INFO @ 17:29:05]   CodeCarbon version: 2.8.3\n[codecarbon INFO @ 17:29:05]   Available RAM : 31.351 GB\n[codecarbon INFO @ 17:29:05]   CPU count: 4\n[codecarbon INFO @ 17:29:05]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n[codecarbon INFO @ 17:29:05]   GPU count: 2\n[codecarbon INFO @ 17:29:05]   GPU model: 2 x Tesla T4\n[codecarbon INFO @ 17:29:08] Saving emissions data to file /kaggle/working/emissions.csv\n<ipython-input-26-2d9dfced9ac1>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n[codecarbon INFO @ 17:29:20] Energy consumed for RAM : 0.000038 kWh. RAM Power : 11.756441116333008 W\n[codecarbon INFO @ 17:29:20] Energy consumed for all CPUs : 0.000139 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 17:29:20] Energy consumed for all GPUs : 0.000255 kWh. Total GPU Power : 78.12395170383596 W\n[codecarbon INFO @ 17:29:20] 0.000433 kWh of electricity used since the beginning.\n","output_type":"stream"},{"name":"stdout","text":"0.9794913863822805\n","output_type":"stream"}],"execution_count":30}]}