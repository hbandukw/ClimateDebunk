{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import argparse\n",
    "import torch\n",
    "import logging\n",
    "import pandas as pd\n",
    "import nlpaug.augmenter.word as naw\n",
    "from sklearn.model_selection import KFold\n",
    "from config import load_config\n",
    "from data_prep import read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_config = load_config('configs/augmentation_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_number(label):\n",
    "    \"\"\"Extracts the leading numeric label from a string.\"\"\"\n",
    "    match = re.match(r\"(\\d+)_\", label)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "\n",
    "def balance_dataset(df, label_column, text_column, augmenter):\n",
    "    \"\"\"\n",
    "    Augments underrepresented classes in a dataset to balance class distribution.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        label_column (str): Name of the column containing class labels.\n",
    "        text_column (str): Name of the column containing text to augment.\n",
    "        augmenter: NLP augmentation object with an 'augment' method.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with balanced class distribution.\n",
    "    \"\"\"\n",
    "    class_counts = df[label_column].value_counts()\n",
    "    max_count = class_counts.max()\n",
    "\n",
    "    augmented_rows = []\n",
    "    for label, deficit in (max_count - class_counts).items():\n",
    "        if deficit > 0:\n",
    "            sample_rows = df[df[label_column] == label].sample(n=deficit, replace=True)\n",
    "            for _, row in sample_rows.iterrows():\n",
    "                augmented_text = augmenter.augment(row[text_column])\n",
    "                augmented_rows.append([augmented_text, label] + row.drop([text_column, label_column]).tolist())\n",
    "\n",
    "    augmented_df = pd.DataFrame(augmented_rows, columns=[text_column, label_column] + \n",
    "                                [col for col in df.columns if col not in [text_column, label_column]])\n",
    "\n",
    "    # Clean up augmented text formatting\n",
    "    augmented_df[text_column] = augmented_df[text_column].astype(str).str.replace(r\"^\\['|'\\]$\", \"\", regex=True)\n",
    "    balanced_df = pd.concat([df, augmented_df], ignore_index=True)\n",
    "    balanced_df['label_column'] = balanced_df['label_column'].astype(int)\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "def main():\n",
    "    # Argument parser setup\n",
    "    parser = argparse.ArgumentParser(description=\"Augments underrepresented classes in a dataset to balance class distribution\")\n",
    "    parser.add_argument(\"--config\", type=str, default=\"configs/augmentation_config.yaml\", help=\"Path to the configuration file.\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Load config\n",
    "    config = load_config(args.config)\n",
    "    \n",
    "    df = pd.read_parquet(config[\"data_path\"])\n",
    "\n",
    "    # Extract numeric labels\n",
    "    df[\"numeric_label\"] = df[\"label\"].apply(extract_number)\n",
    "\n",
    "    # Set device\n",
    "    device = config[\"device\"] if config[\"device\"] in [\"cuda\", \"cpu\"] else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Define augmentation model\n",
    "    augmenter = naw.ContextualWordEmbsAug(\n",
    "        model_path=config[\"augmenter_model\"],\n",
    "        action=config[\"augment_action\"],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Create output directory\n",
    "    os.makedirs(config[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "    # K-Fold splitting & augmentation\n",
    "    kf = KFold(n_splits=config[\"n_splits\"], shuffle=True, random_state=config[\"random_seed\"])\n",
    "    \n",
    "    for i, (_, test_index) in enumerate(kf.split(df), start=1):\n",
    "        subset = df.iloc[test_index]\n",
    "        balanced_subset = balance_dataset(subset, \"numeric_label\", \"quote\", augmenter)\n",
    "\n",
    "        subset_path = os.path.join(config[\"output_dir\"], f\"df{i}.csv\")\n",
    "        balanced_path = os.path.join(config[\"output_dir\"], f\"df_balanced{i}.csv\")\n",
    "\n",
    "        subset.to_csv(subset_path, index=False)\n",
    "        balanced_subset.to_csv(balanced_path, index=False)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
