{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10471355,"sourceType":"datasetVersion","datasetId":6483657}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install nlpaug","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T18:17:51.239711Z","iopub.execute_input":"2025-01-27T18:17:51.240044Z","iopub.status.idle":"2025-01-27T18:17:56.666568Z","shell.execute_reply.started":"2025-01-27T18:17:51.240006Z","shell.execute_reply":"2025-01-27T18:17:56.665396Z"}},"outputs":[{"name":"stdout","text":"Collecting nlpaug\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.26.4)\nRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.2.2)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.32.3)\nRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.16.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.12.14)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.6)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.2->nlpaug) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nlpaug\nSuccessfully installed nlpaug-1.1.11\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom sklearn.model_selection import train_test_split, KFold\nimport pandas as pd\nimport numpy as np\nimport re\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\nimport nlpaug.augmenter.word as naw\nfrom sklearn.model_selection import KFold\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T18:18:12.726579Z","iopub.execute_input":"2025-01-27T18:18:12.727013Z","iopub.status.idle":"2025-01-27T18:19:13.131270Z","shell.execute_reply.started":"2025-01-27T18:18:12.726979Z","shell.execute_reply":"2025-01-27T18:19:13.130376Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T18:19:29.684605Z","iopub.execute_input":"2025-01-27T18:19:29.685220Z","iopub.status.idle":"2025-01-27T18:19:29.689100Z","shell.execute_reply.started":"2025-01-27T18:19:29.685193Z","shell.execute_reply":"2025-01-27T18:19:29.688260Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def extract_number(label):\n    match = re.match(r'(\\d+)_', label)\n    if match:\n        return int(match.group(1))  \n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T18:19:47.551526Z","iopub.execute_input":"2025-01-27T18:19:47.551826Z","iopub.status.idle":"2025-01-27T18:19:47.556401Z","shell.execute_reply.started":"2025-01-27T18:19:47.551806Z","shell.execute_reply":"2025-01-27T18:19:47.555495Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = pd.read_parquet('/kaggle/input/train-parquet/train.parquet')\ndf['numeric_label'] = df['label'].apply(extract_number)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T18:19:49.168798Z","iopub.execute_input":"2025-01-27T18:19:49.169076Z","iopub.status.idle":"2025-01-27T18:19:49.206923Z","shell.execute_reply.started":"2025-01-27T18:19:49.169054Z","shell.execute_reply":"2025-01-27T18:19:49.206246Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"n_splits = 5\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\nsubsets = []\nfor train_index, test_index in kf.split(df):\n    # Creating subsets based on the indices: here, we use 'test_index' for simplicity\n    # to denote that these are just the split parts, not actually 'testing' data.\n    subset = df.iloc[test_index]\n    subsets.append(subset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T18:20:13.822765Z","iopub.execute_input":"2025-01-27T18:20:13.823057Z","iopub.status.idle":"2025-01-27T18:20:13.836032Z","shell.execute_reply.started":"2025-01-27T18:20:13.823032Z","shell.execute_reply":"2025-01-27T18:20:13.835291Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df1 = subsets[0]\ndf2 = subsets[1]\ndf3 = subsets[2]\ndf4 = subsets[3]\ndf5 = subsets[4]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T18:21:44.654660Z","iopub.execute_input":"2025-01-27T18:21:44.654953Z","iopub.status.idle":"2025-01-27T18:21:44.659136Z","shell.execute_reply.started":"2025-01-27T18:21:44.654932Z","shell.execute_reply":"2025-01-27T18:21:44.658178Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T18:48:06.539435Z","iopub.execute_input":"2025-01-27T18:48:06.539857Z","iopub.status.idle":"2025-01-27T18:48:06.545346Z","shell.execute_reply.started":"2025-01-27T18:48:06.539828Z","shell.execute_reply":"2025-01-27T18:48:06.544265Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"aug = naw.ContextualWordEmbsAug(\n    model_path='bert-base-uncased',\n    action='substitute',\n    device='cuda' if torch.cuda.is_available() else 'cpu'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T18:22:54.728952Z","iopub.execute_input":"2025-01-27T18:22:54.729262Z","iopub.status.idle":"2025-01-27T18:23:00.380031Z","shell.execute_reply.started":"2025-01-27T18:22:54.729237Z","shell.execute_reply":"2025-01-27T18:23:00.379010Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bbcbda1a1754d11a29ecfca424e9b58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80975d3adf52481792e773d6362be062"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8acafa180a494345be99359bda1c629a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a290c637a01a41ffa2cb109c1ba9ccf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b891c3048904517bebbe144a65fafd4"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"def balance_dataset(train_df, label_column, text_column, augmenter):\n    \"\"\"\n    Augments underrepresented classes in a dataset to balance class distribution.\n\n    Args:\n    - train_df (pd.DataFrame): DataFrame containing the data.\n    - label_column (str): Name of the column containing class labels.\n    - text_column (str): Name of the column containing text to augment.\n    - augmenter: Text augmentation object with an 'augment' method.\n\n    Returns:\n    - pd.DataFrame: A DataFrame with balanced class distribution.\n    \"\"\"\n    # Count each class's occurrences\n    class_counts = train_df[label_column].value_counts()\n    max_count = class_counts.max()\n\n    # Calculate how many samples each class needs to be balanced\n    augment_counts = max_count - class_counts\n    augmented_rows = []\n\n    # Perform augmentation for underrepresented classes\n    for label, deficit in augment_counts.items():\n        if deficit > 0:\n            # Sample from the existing rows of the class\n            sample_rows = train_df[train_df[label_column] == label].sample(n=deficit, replace=True)\n            for _, row in sample_rows.iterrows():\n                augmented_text = augmenter.augment(row[text_column])\n                # Create a new row with the augmented text and the same label\n                augmented_rows.append([augmented_text, label] + row.drop([text_column, label_column]).tolist())\n\n    # Create a DataFrame from the augmented rows\n    augmented_df = pd.DataFrame(augmented_rows, columns=[text_column, label_column] + [col for col in train_df.columns if col not in [text_column, label_column]])\n    \n    # Clean up and concat with original DataFrame\n    augmented_df[text_column] = augmented_df[text_column].astype(str)\n    augmented_df[text_column] = augmented_df[text_column].str.replace(r\"^\\['|'\\]$\", '', regex=True)\n    df_balanced = pd.concat([train_df, augmented_df], ignore_index=True)\n    df_balanced[label_column] = df_balanced[label_column].astype(int)\n    \n    return df_balanced","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T18:48:10.579335Z","iopub.execute_input":"2025-01-27T18:48:10.579692Z","iopub.status.idle":"2025-01-27T18:48:10.586773Z","shell.execute_reply.started":"2025-01-27T18:48:10.579649Z","shell.execute_reply":"2025-01-27T18:48:10.585880Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"df_balanced1 = balance_dataset(df1, 'numeric_label', 'quote', aug)\ndf1.to_csv('df1.csv', index=False)\ndf_balanced1.to_csv('df_balanced1.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T18:32:24.336651Z","iopub.execute_input":"2025-01-27T18:32:24.336947Z","iopub.status.idle":"2025-01-27T18:32:24.385279Z","shell.execute_reply.started":"2025-01-27T18:32:24.336925Z","shell.execute_reply":"2025-01-27T18:32:24.384606Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"df_balanced2 = balance_dataset(df2, 'numeric_label', 'quote', aug)\ndf2.to_csv('df2.csv', index=False)\ndf_balanced2.to_csv('df_balanced2.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_balanced3 = balance_dataset(df3, 'numeric_label', 'quote', aug)\ndf3.to_csv('df3.csv', index=False)\ndf_balanced3.to_csv('df_balanced3.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_balanced4 = balance_dataset(df4, 'numeric_label', 'quote', aug)\ndf4.to_csv('df4.csv', index=False)\ndf_balanced4.to_csv('df_balanced4.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_balanced5 = balance_dataset(df5, 'numeric_label', 'quote', aug)\ndf5.to_csv('df5.csv', index=False)\ndf_balanced5.to_csv('df_balanced5.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}